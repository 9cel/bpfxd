import bpf (..)
import ffi as c (C!)
import ptr
import os (..)
import atomic
import ty
import time
import chalk (chalk)
import path (Path)
import errno
import sh (sh)
import dwarf
import log (..)
import pretty
import ty.parse as parse

const TRACEFS_PATH = '/sys/kernel/debug/tracing'

const RING_BUFFER_CAPACITY = (16  * 1024 * 1024)
const PER_CPU_SCRATCH      = (256 * 1024)
const STACK_TRACE_SIZE     = (127 * 8)
const MAX_STACK_TRACES     = (16  * 1024)

// Distinct colors for registers in disassembly
chalk.r0  = '#e45d44'
chalk.r1  = '#44e48a'
chalk.r2  = '#66a8e4'
chalk.r3  = '#3466e4'
chalk.r4  = '#a8e445'
chalk.r5  = '#66d19a'
chalk.r6  = '#bb66e4'
chalk.r7  = '#86c6d1'
chalk.r8  = '#cc66d1'
chalk.r9  = '#d86666'
chalk.r10 = '#d1d166'

chalk.jmp    = '#a8e445'
chalk.call   = '#cc66d1'
chalk.exit   = '#66d19a'

chalk.ld_map_value = '#a466d1'
chalk.ld_map_fd    = '#a466d1'

const SYS_perf_event_open = 298

const PAGE_SIZE = 4096

const PERF_TYPE_TRACEPOINT    = 2
const PERF_TYPE_SOFTWARE      = 1
const PERF_COUNT_SW_CPU_CLOCK = 0
const PERF_EVENT_IOC_ENABLE   = 0x2400
const PERF_EVENT_IOC_DISABLE  = 0x2401
const PERF_EVENT_IOC_SET_BPF  = 0x40042408

const r0  = BPF_REG_0
const r1  = BPF_REG_1
const r2  = BPF_REG_2
const r3  = BPF_REG_3
const r4  = BPF_REG_4
const r5  = BPF_REG_5
const r6  = BPF_REG_6
const r7  = BPF_REG_7
const r8  = BPF_REG_8
const r9  = BPF_REG_9
const rbp = BPF_REG_10

class BpfError < RuntimeError {
}

C! struct perf_event_attr {
    __u32 type;
    __u32 size;
    __u64 config;
    __u64 sample_period_or_freq;
    __u64 sample_type;
    __u64 read_format;
    __u64 flags;
    __u32 wakeup_events_or_watermark;
    __u32 bp_type;
    __u64 bp_addr_or_config1;
    __u64 bp_len_or_config2;
    __u64 branch_sample_type;
    __u64 sample_regs_user;
    __u32 sample_stack_user;
    __s32 clockid;
    __u64 sample_regs_intr;
    __u32 aux_watermark;
    __u16 sample_max_stack;
    __u16 __reserved_2;
};

use CType = {
    ?ident: String | nil,
    ?name: String | nil,
    ?const?: Bool,
    ?volatile?: Bool,
    ?restrict?: Bool,
    ?pointee: CType | nil,
    ?count: Int | nil
}

fn c-parse(field: String) -> CType {
    const token = /(\s+|\*|\[\d*\]|struct \w+)/
    const qualifiers = ['const', 'volatile', 'restrict']

    let parts = field.scan(/\*|struct \w+|unsigned \w+|\w+/).reverse()

    fn get-qualifiers(
        const?: Bool = false,
        volatile?: Bool = false,
        restrict?: Bool = false
    ) -> (Bool, Bool, Bool) {
        while (#parts > 0) && (parts[-1] in qualifiers) {
            match parts.pop() {
                'const'    => { const?    = true }
                'volatile' => { volatile? = true }
                'restrict' => { restrict? = true }
            }
        }
        (const?, volatile?, restrict?)
    }

    let (const?, volatile?, restrict?) = get-qualifiers()

    let name = parts.pop()
    while (#parts > 1) && (parts[-1] not in qualifiers) && (parts[-1] != '*') {
        let part = parts.pop()
        name = "{part} {name}"
    }

    (const?, volatile?, restrict?) = get-qualifiers(const?, volatile?, restrict?)

    fn go(t0: CType) -> CType {
        if #parts == 0 {
            return t0
        }

        let (const?, volatile?, restrict?) = get-qualifiers()

        match parts.pop() {
            '*'   => { return {*go({*t0, pointee: t0, name: '*'}), const?, volatile?, restrict?} },
            ident => { return {*t0, ident} }
        }
    }

    go({name, const?, volatile?, restrict?})
}

class Moment {
    __t: Float

    init(t: Float | Int) {
        __t = float(t ?? time.now())
    }

    __fmt__(fmt: String) -> String {
        time.strftime(fmt, int(__t))
    }

    __str__() -> String {
        __fmt__("%Y-%m-%d %H:%M:%S")
    }
}

class BpfJump {
    __prog:     BpfAssembler
    __byte-off: Int
    __insn-off: Int
    __id:       Int

    init(prog: BpfAssembler, byte-off: Int, insn-off: Int, id: Int) {
        __prog     = prog
        __byte-off = byte-off
        __insn-off = insn-off
        __id       = id
    }

    patch() {
        __prog.patch-jump(__byte-off, __insn-off, __id)
    }
}

class BpfJumpPair < BpfJump {
    __one: BpfJump
    __two: BpfJump

    init(one, two) {
        __one = one
        __two = two
    }

    patch() {
        __one.patch()
        __two.patch()
    }
}

class BpfAssembler {
    __count: Int
    __prog:  Blob
    __dis:   Blob
    __label: Int

    init() {
        __count = 0
        __prog  = Blob()
        __dis   = Blob()
        __label = 0
    }

    __ptr__() -> Ptr[_] {
        __prog.ptr()
    }

    #() -> Int {
        __count
    }

    __emit(code: Int, dst: Int, src: Int, off: Int, imm: Int, imm2: Int = 0) {
        __prog.push(code)

        __prog.push(
            ((dst & 0x0F) << 0)
          | ((src & 0x0F) << 4)
        )

        __prog.push((off >> 0) & 0xFF)
        __prog.push((off >> 8) & 0xFF)

        __prog.push((imm >> 0) & 0xFF)
        __prog.push((imm >> 8) & 0xFF)
        __prog.push((imm >> 16) & 0xFF)
        __prog.push((imm >> 24) & 0xFF)

        if code == 0x18 {
            __prog.push(0)
            __prog.push(0)
            __prog.push(0)
            __prog.push(0)
            __prog.push((imm2 >> 0) & 0xFF)
            __prog.push((imm2 >> 8) & 0xFF)
            __prog.push((imm2 >> 16) & 0xFF)
            __prog.push((imm2 >> 24) & 0xFF)
            __count += 1
        }

        __count += 1
    }

    __d(text: String) {
        let parts = text.scan(/^\w+|if|atomic|r\d+|map\d+|L\d+|i\d+|u\d+|-?\d+|./)
        let parts = parts.map(p -> match p {
            /r(\d+)/      => chalk"[{p}]{p}[/]",
            /map(\d+)/    => chalk"[{p}?]{p}[/]",
            /L(\d+)/      => chalk"[{p}?]{p}[/]",
            /^-?\d+$/     => chalk"[magenta]{p}[/]",
            /^(i|u)\d+$/  => chalk"[cyan]{p}[/]",
            'if'          => chalk"[#888888]{p}[/]",
            'atomic'      => chalk"[#f05668]{p}[/]",
            /^.$/         => p,
            _             => chalk"[{p}]{p}[/]",
        })
        __dis.push("  {#self:04}  {parts.join()}\n")
    }

    ld64(dst: Int, imm: Int) {
        __d("r{dst} = {imm}")
        __emit(BPF_LD | BPF_IMM | BPF_DW, dst, 0, 0, imm)
    }

    ld_map_fd(dst: Int, fd: Int) {
        __d("r{dst} = map{fd}")
        __emit(BPF_LD | BPF_IMM | BPF_DW, dst, BPF_PSEUDO_MAP_FD, 0, fd)
    }

    ld_map_value(dst: Int, fd: Int, off: Int) {
        __d("r{dst} = *(map{fd}[0]{off:+})")
        __emit(BPF_LD | BPF_IMM | BPF_DW, dst, BPF_PSEUDO_MAP_VALUE, 0, fd, off)
    }

    imov64(dst: Int, imm: Int) {
        __d("r{dst} = {imm}")
        __emit(BPF_ALU64 | BPF_MOV | BPF_K, dst, 0, 0, imm)
    }

    mov64(dst: Int, src: Int) {
        __d("r{dst} = r{src}")
        __emit(BPF_ALU64 | BPF_MOV | BPF_X, dst, src, 0, 0)
    }

    mov32(dst: Int, src: Int) {
        __d("r{dst} = (u32)r{src}")
        __emit(BPF_ALU | BPF_MOV | BPF_X, dst, src, 0, 0)
    }

    mov16(dst: Int, src: Int) {
        __d("r{dst} = (u16)r{src}")
        __emit(BPF_ALU | BPF_MOV | BPF_X, dst, src, 0, 0)
    }

    mov8(dst: Int, src: Int) {
        __d("r{dst} = (u8)r{src}")
        __emit(BPF_ALU | BPF_MOV | BPF_X, dst, src, 0, 0)
    }

    add64(dst: Int, src: Int) {
        __d("r{dst} += r{src}")
        __emit(BPF_ALU64 | BPF_ADD | BPF_X, dst, src, 0, 0)
    }

    add64i(dst: Int, imm: Int) {
        __d("r{dst} += {imm}")
        __emit(BPF_ALU64 | BPF_ADD | BPF_K, dst, 0, 0, imm)
    }

    mul64(dst: Int, src: Int) {
        __d("r{dst} *= r{src}")
        __emit(BPF_ALU64 | BPF_MUL | BPF_X, dst, src, 0, 0)
    }

    imul64i(dst: Int, imm: Int) {
        __d("r{dst} *= {imm}")
        __emit(BPF_ALU64 | BPF_MUL | BPF_K, dst, 0, 0, imm)
    }

    sub64(dst: Int, src: Int) {
        __d("r{dst} -= r{src}")
        __emit(BPF_ALU64 | BPF_SUB | BPF_X, dst, src, 0, 0)
    }

    sub64i(dst: Int, imm: Int) {
        __d("r{dst} -= {imm}")
        __emit(BPF_ALU64 | BPF_SUB | BPF_K, dst, 0, 0, imm)
    }

    div64(dst: Int, src: Int) {
        __d("r{dst} /= r{src}")
        __emit(BPF_ALU64 | BPF_DIV | BPF_X, dst, src, 0, 0)
    }

    and64i(dst: Int, imm: Int) {
        __d("r{dst} &= {imm}")
        __emit(BPF_ALU64 | BPF_AND | BPF_K, dst, 0, 0, imm)
    }

    and64(dst: Int, src: Int) {
        __d("r{dst} &= r{src}")
        __emit(BPF_ALU64 | BPF_AND | BPF_X, dst, src, 0, 0)
    }

    or64(dst: Int, src: Int) {
        __d("r{dst} |= r{src}")
        __emit(BPF_ALU64 | BPF_OR | BPF_X, dst, src, 0, 0)
    }

    shr64i(dst: Int, imm: Int) {
        __d("r{dst} >>= {imm}")
        __emit(BPF_ALU64 | BPF_RSH | BPF_K, dst, 0, 0, imm)
    }

    shl64i(dst: Int, imm: Int) {
        __d("r{dst} <<= {imm}")
        __emit(BPF_ALU64 | BPF_LSH | BPF_K, dst, 0, 0, imm)
    }

    exit() {
        __d("exit")
        __emit(BPF_JMP | BPF_EXIT, 0, 0, 0, 0)
    }

    label() -> (Int, Int) {
        __dis.push(str(chalk"[L{__label}?]L{__label}[/]:\n"))
        (#self, __label++)
    }

    __jmp(op: Int, dst: Int, src: Int, off: Int, imm: Int) {
        __emit(BPF_JMP | op, dst, src, off, imm)
        BpfJump(self, #__prog - 8, #self - 1, __label++)
    }

    jmp64(imm: Int = 0, to: (Int, Int) = nil) -> BpfJump {
        match to {
            (pos, id) => {
                __d("jmp L{id}")
                __emit(BPF_JMP | BPF_JA, 0, 0, pos - #self - 1, 0)
            },

            _ => {
                __d("jmp L{__label}")
                __jmp(BPF_JA, 0, 0, imm, 0)
            }
        }
    }

    jeq64(dst: Int, imm: Int = 0) -> BpfJump {
        __d("jmp L{__label} if r{dst} == {imm}")
        __jmp(BPF_JEQ | BPF_K, dst, 0, 0, imm)
    }

    jeq64x(dst: Int, src: Int) -> BpfJump {
        __d("jmp L{__label} if r{dst} == r{src}")
        __jmp(BPF_JEQ | BPF_X, dst, src, 0, 0)
    }

    jne64(dst: Int, imm: Int = 0) -> BpfJump {
        __d("jmp L{__label} if r{dst} != {imm}")
        __jmp(BPF_JNE | BPF_K, dst, 0, 0, imm)
    }

    jgt64(dst: Int, imm: Int = 0) -> BpfJump {
        __d("jmp L{__label} if r{dst} > {imm}")
        __jmp(BPF_JGT | BPF_K, dst, 0, 0, imm)
    }

    jsgt64(dst: Int, imm: Int = 0) -> BpfJump {
        __d("jmp L{__label} if r{dst} > {imm}")
        __jmp(BPF_JSGT | BPF_K, dst, 0, 0, imm)
    }

    jsgt64x(dst: Int, src: Int) -> BpfJump {
        __d("jmp L{__label} if r{dst} > r{src}")
        __jmp(BPF_JSGT | BPF_X, dst, src, 0, 0)
    }

    jge64(dst: Int, imm: Int = 0) -> BpfJump {
        __d("jmp L{__label} if r{dst} >= {imm}")
        __jmp(BPF_JGE | BPF_K, dst, 0, 0, imm)
    }

    jle64(dst: Int, imm: Int = 0) -> BpfJump {
        __d("jmp L{__label} if r{dst} <= {imm}")
        __jmp(BPF_JLE | BPF_K, dst, 0, 0, imm)
    }

    jsle64(dst: Int, imm: Int = 0) -> BpfJump {
        __d("jmp L{__label} if r{dst} <= {imm}")
        __jmp(BPF_JSLE | BPF_K, dst, 0, 0, imm)
    }

    jle64x(dst: Int, src: Int) -> BpfJump {
        __d("jmp L{__label} if r{dst} <= r{src}")
        __jmp(BPF_JLE | BPF_X, dst, src, 0, 0)
    }

    jsle64x(dst: Int, src: Int) -> BpfJump {
        __d("jmp L{__label} if r{dst} <= r{src}")
        __jmp(BPF_JSLE | BPF_X, dst, src, 0, 0)
    }

    jne64x(dst: Int, src: Int) -> BpfJump {
        __d("jmp L{__label} if r{dst} != r{src}")
        __jmp(BPF_JNE | BPF_X, dst, src, 0, 0)
    }

    sti8(dst: Int, imm: Int, off: Int = 0) {
        __d("*(u8 *)(r{dst}{off:+}) = {imm}")
        __emit(BPF_ST | BPF_MEM | BPF_B, dst, 0, off, imm)
    }

    stx8(dst: Int, src: Int, off: Int = 0) {
        __d("*(u8 *)(r{dst}{off:+}) = r{src}")
        __emit(BPF_STX | BPF_MEM | BPF_B, dst, src, off, 0)
    }

    stx16(dst: Int, src: Int, off: Int = 0) {
        __d("*(u16 *)(r{dst}{off:+}) = r{src}")
        __emit(BPF_STX | BPF_MEM | BPF_H, dst, src, off, 0)
    }

    stx32(dst: Int, src: Int, off: Int = 0) {
        __d("*(u32 *)(r{dst}{off:+}) = r{src}")
        __emit(BPF_STX | BPF_MEM | BPF_W, dst, src, off, 0)
    }

    stx64(dst: Int, src: Int, off: Int = 0) {
        if off % 8 != 0 {
            throw BpfError("stx64: offset must be multiple of 8")
        }
        __d("*(u64 *)(r{dst}{off:+}) = r{src}")
        __emit(BPF_STX | BPF_MEM | BPF_DW, dst, src, off, 0)
    }

    ldx8(dst: Int, src: Int, off: Int = 0) {
        __d("r{dst} = *(u8 *)(r{src}+{off})")
        __emit(BPF_LDX | BPF_MEM | BPF_B, dst, src, off, 0)
    }

    ldx16(dst: Int, src: Int, off: Int = 0) {
        __d("r{dst} = *(u16 *)(r{src}{off:+})")
        __emit(BPF_LDX | BPF_MEM | BPF_H, dst, src, off, 0)
    }

    ldx32(dst: Int, src: Int, off: Int = 0) {
        __d("r{dst} = *(u32 *)(r{src}{off:+})")
        __emit(BPF_LDX | BPF_MEM | BPF_W, dst, src, off, 0)
    }

    ldx64(dst: Int, src: Int, off: Int = 0) {
        __d("r{dst} = *(u64 *)(r{src}{off:+})")
        __emit(BPF_LDX | BPF_MEM | BPF_DW, dst, src, off, 0)
    }

    patch-jump(byte-off: Int, insn-off: Int, id: Int) {
        let offset = #self - insn-off - 1
        let ptr = __prog.ptr() + byte-off + 2
        c.store(c.u16, ptr, offset)
        __dis.push(str(chalk"[L{id}?]L{id}[/]:\n"))
    }

    call(func: Int) {
        __d("call {helper.names[func]}")
        __emit(BPF_JMP | BPF_CALL, 0, 0, 0, func)
    }

    fetch-add(dst: Int, src: Int) {
        __d("*(atomic u64 *)r{dst} += r{src}")
        __emit(BPF_STX | BPF_ATOMIC | BPF_DW, dst, src, 0, BPF_ADD | BPF_FETCH)
    }

    note(text: _) {
        __dis.push(str(chalk"[#777]// {text}[/]\n"))
    }

    dis -> String {
        __dis.str()
    }

    hex -> String {
        __prog.list().map(\"{_:02x}").groups-of(8).map(&unwords).unlines()
    }
}

tag UnknownPtr, MapPtr, KernelPtr, UserPtr, StackPtr;
tag U8, U16, U32, U64;
tag I8, I16, I32, I64;
tag Str;
tag Time64;
tag Struct;
tag Record;
tag RingBuffer;
tag BloomFilter;
tag Histogram;
tag UStack;
tag KStack;
tag MapRef;
tag Hash;
tag StackMap;
tag UnknownType;
tag Unit;
tag Const;

macro AnyMap = RingBuffer or BloomFilter or StackMap or Hash(_, _)
macro AnyPtr(t) = UnknownPtr($$t) or MapPtr($$t) or KernelPtr($$t) or UserPtr($$t) or StackPtr($$t, _)
macro AnyInt = U8 or U16 or U32 or U64 or I8 or I16 or I32 or I64 or Const(_)
use match StringLike = AnyPtr(I8 or Str(_)) or Str(_) => ()

use BpfType =
    UnknownPtr[BpfType]
  | MapPtr[BpfType]
  | KernelPtr[BpfType]
  | UserPtr[BpfType]
  | StackPtr[(BpfType, Int)]
  | RingBuffer
  | BloomFilter
  | StackMap
  | UStack
  | KStack
  | Histogram
  | Hash[(BpfType, BpfType)]
  | MapRef[map.BpfMap]
  | U8
  | U16
  | U32
  | U64
  | I8
  | I16
  | I32
  | I64
  | Time64
  | Const[Int]
  | Record[Array[BpfType]]
  | Struct[Dict[String, (Int, BpfType)]]
  | Str[Int]
  | Unit
  | UnknownType
  | nil

fn signed?(t: BpfType) -> Bool {
    match t {
        I8, I16, I32, I64 => true,
        _                 => false
    }
}

fn align(n: Int) -> Int {
    (n & 7) ? ((n + 8) & ~7) : n
}

pub fn size-of(t: BpfType) -> Int {
    match t {
        U8  or I8   => 1,
        U16 or I16  => 2,
        U32 or I32  => 4,
        U64 or I64  => 8,
        Time64      => 8,
        AnyPtr(_)   => 8,
        Const(_)    => 0,
        Str(n)      => n,
        Histogram   => 512,
        UStack      => 8,
        KStack      => 8,
        MapRef(_)   => 0,
        Record(ts)  => ts.map(align . size-of).sum(0),
        Unit        => 0
    }
}

let c-type-map = %{
    'unsigned char': U8,
    'unsigned short': U16,
    'unsigned int': U32,
    'unsigned long': U64,
    'char': I8,
    'short': I16,
    'int': I32,
    'long': I64,

    'u64': U64,
    'u32': U32,
    'u16': U16,

    'size_t': U64,
    'ssize_t': I64,

    'off_t': I64,
    'pid_t': I32,

    'umode_t': U32
}

fn c-to-bpf(t: CType) -> BpfType {
    match t {
        {pointee: $t, *} => UserPtr(c-to-bpf(t)),

        {name, *} => {
            if let $bpf-type = c-type-map[name] {
                bpf-type
            } else {
                return UnknownType
                throw BpfError("unsupported C type name: {name}")
            }
        },

        _ => throw BpfError("unsupported C type: {t}")
    }
}

fn ffi-to-bpf(type: CType[Any]) -> BpfType {
    match type {
        c.char  => I8,
        c.u8    => U8,
        c.u16   => U16,
        c.u32   => U32,
        c.u64   => U64,
        c.i8    => I8,
        c.i16   => I16,
        c.i32   => I32,
        c.i64   => I64,
        c.int   => I32,
        c.uint  => U32,
        c.long  => I64,
        c.ulong => U64,
        c.ptr   => UserPtr(U8),
        _       => throw BpfError("unsupported FFI type: {type}")
    }
}

fn ty-to-bpf(t: AST) -> BpfType {
    match t {
        ty.Id({name, *}) => {
            match name {
                'u8'      => U8,
                'u16'     => U16,
                'u32'     => U32,
                'u64'     => U64,
                'i8'      => I8,
                'i16'     => I16,
                'i32'     => I32,
                'i64'     => I64,
                'size_t'  => U64,
                'ssize_t' => I64,
                'pid_t'   => I32,
                'str'     => UnknownPtr(I8),
                _         => do {
                    try {
                        let type = ty.eval(name)
                        match type {
                            type: Ptr => ty-to-bpf(type),

                            _ and let $fields = type.?fields => {
                                Struct(%{
                                    name: (off, ffi-to-bpf(type))
                                    for (name, off, type) in fields
                                })
                            },

                            _ => nil
                        }
                    } catch _ {
                        throw BpfError("unsupported type: {name}")
                    }
                }
            }
        },

        ty.Subscript(
            ty.Id({name: 'hash', *}),
            [k0, v0]
        ) => {
            Hash(ty-to-bpf(k0), ty-to-bpf(v0))
        },

        ty.Subscript(
            ty.Id({name: 'str', *}),
            ty.Int(n)
        ) => {
            Str(n)
        },

        ty.Subscript(ty.Id({name: 'ptr', *}), t) => {
            UserPtr(ty-to-bpf(t))
        },

        ty.Array([ty.ArrayItem({item, *})]) => {
            UnknownPtr(ty-to-bpf(item))
        },

        _ => throw BpfError("unsupported type: {t}")
    }
}


fn ctx-arg-type(decl: String) -> (String | nil, BpfType) {
    match c-parse(decl) {
        {pointee: $t, const?, ?ident, *} => do {
            if const? {
                (ident, KernelPtr(c-to-bpf(t)))
            } else {
                (ident, UserPtr(c-to-bpf(t)))
            }
        },

        {name: $name, ?ident, *} => do {
            if let $bpf-type = c-type-map[name] {
                (ident, bpf-type)
            } else {
                throw BpfError("unsupported C type in syscall arg: {name}")
            }
        },

        t => do { throw BpfError("unsupported C type in syscall arg: {t}") }
    }
}

fn deref-ptr-type(t0: BpfType) -> BpfType {
    match t0 {
        Str(_)     => t0,
        StringLike => Str(128),
        AnyPtr(t1) => t1,
        Record(ts) => Record(ts.map(deref-ptr-type)),
        _          => t0
    }
}


class Var : Slot {
    __off:  Int
    __name: String
    __prog: BpfProgram
    type:   BpfType
    map:    _

    init(name: String, off: Int, prog: BpfProgram) {
        debug!("new var: {name} @ {off}")
        __name = name
        __off  = off
        __prog = prog
    }

    off -> Int {
        __off
    }

    name -> String {
        __name
    }

    map? -> Bool {
        match type {
            AnyMap => true,
            _      => false
        }
    }

    local? -> Bool {
        (map == nil)
    }

    load(dst: Int) {
        match type {
            U8  or I8  => __prog.asm.ldx8(dst, rbp, -__off),
            U16 or I16 => __prog.asm.ldx16(dst, rbp, -__off),
            U32 or I32 => __prog.asm.ldx32(dst, rbp, -__off),
            _          => __prog.asm.ldx64(dst, rbp, -__off)
        }
    }

    store(src: Int) {
        match type {
            U8  or I8  => __prog.asm.stx8(rbp, src, -__off),
            U16 or I16 => __prog.asm.stx16(rbp, src, -__off),
            U32 or I32 => __prog.asm.stx32(rbp, src, -__off),
            _          => __prog.asm.stx64(rbp, src, -__off)
        }
    }

    load-addr(dst: Int) {
        __prog.asm.mov64(dst, rbp)
        __prog.asm.add64i(dst, -__off)
    }

    spill() -> Slot {
        self
    }
}

use Expr = {
    ast: AST
    type: BpfType
}

trait Slot {
    load(dst: Int) -> _;
    load-addr(dst: Int) -> _;
    store(src: Int) -> _;
    spill() -> Slot;
    zero() -> Any;
    copy-into-stack(off: Int, type: BpfType);
}

class RegZeroSlot : Slot {
    __prog: BpfProgram

    init(prog: BpfProgram) {
        __prog = prog
    }

    load(dst: Int) {
        if dst != r0 {
            __prog.asm.mov64(dst, r0)
        }
    }

    store(src: Int) {
        if src != r0 {
            __prog.asm.mov64(r0, src)
        }
    }

    spill() -> Slot {
        let slot = __prog.alloc(8)
        slot.store(r0)
        slot
    }

    load-addr(dst: Int) {
        spill().load-addr(dst)
    }

    zero() -> Any {
        __prog.asm.imov64(r0, 0)
    }

    copy-into-stack(off: Int, type: BpfType) {
        load(r0)
        __prog.store(rbp, off, type, r0)
    }
}

class StackSlot : Slot {
    __off:   Int
    __size:  Int
    __alloc: StackAllocator
    __asm:   BpfAssembler
    __live:  Bool
    ctx:     _

    init(
        off:   Int,
        size:  Int,
        alloc: StackAllocator,
        asm:   BpfAssembler
    ) {
        __off   = off
        __size  = size
        __alloc = alloc
        __asm   = asm
        __live  = true
        try {
            throw BpfError('')
        } catch e {
            ctx = e.trace()
        }
    }

    off -> Int {
        __off
    }

    size -> Int {
        __size
    }

    load(dst: Int) {
        match __size {
            1 => __asm.ldx8(dst, rbp, -__off),
            2 => __asm.ldx16(dst, rbp, -__off),
            4 => __asm.ldx32(dst, rbp, -__off),
            8 => __asm.ldx64(dst, rbp, -__off),
            _ => throw BpfError("unsupported stack slot size: {__size}")
        }
    }

    store(src: Int) {
        match __size {
            1 => __asm.stx8(rbp, src, -__off),
            2 => __asm.stx16(rbp, src, -__off),
            4 => __asm.stx32(rbp, src, -__off),
            8 => __asm.stx64(rbp, src, -__off),
            _ => throw BpfError("unsupported stack slot size: {__size}")
        }
    }

    load-addr(dst: Int) {
        __asm.mov64(dst, rbp)
        __asm.add64i(dst, -__off)
    }

    spill() -> Slot {
        self
    }

    zero() -> Any {
        let quot = __size / 8
        let rem  = __size % 8
        __asm.imov64(r0, 0)
        for i in ..quot {
            __asm.stx64(rbp, r0, -__off + (i * 8))
        }
        if rem >= 4 {
            __asm.stx32(rbp, r0, -__off + (quot * 8))
            rem -= 4
        }
        if rem >= 2 {
            __asm.stx16(rbp, r0, -__off + (quot * 8) + (4 - rem))
            rem -= 2
        }
        if rem >= 1 {
            __asm.stx8(rbp, r0, -__off + (quot * 8) + (4 - rem) + (2 - rem))
            rem -= 1
        }
    }

    copy-into-stack(off: Int, type: BpfType) {
        // r0: source
        __asm.mov64(r0, rbp)
        __asm.add64i(r0, -__off)
        // Remove one level of indirection for string-like types
        if matches?(type, StringLike) {
            __asm.ldx64(r0, r0, 0)
        }

        // r1: destination
        __asm.mov64(r1, rbp)
        __asm.add64i(r1, off)

        let size = size-of(type)
        let quot = size / 8
        let rem  = size % 8

        for i in ..quot {
            __asm.ldx64(r2, r0, i * 8)
            __asm.stx64(r1, r2, i * 8)
        }

        if rem >= 4 {
            __asm.ldx32(r2, r0, quot * 8)
            __asm.stx32(r1, r2, quot * 8)
            rem -= 4
        }
        if rem >= 2 {
            __asm.ldx16(r2, r0, quot * 8 + (4 - rem))
            __asm.stx16(r1, r2, quot * 8 + (4 - rem))
            rem -= 2
        }
        if rem >= 1 {
            __asm.ldx8(r2, r0, quot * 8 + (4 - rem) + (2 - rem))
            __asm.stx8(r1, r2, quot * 8 + (4 - rem) + (2 - rem))
            rem -= 1
        }
    }

    __enter__() { self }

    __drop__() {
        if __live {
            __live = false
            __alloc.free(self)
        }
    }
}

class EmptySlot : Slot {
    init() {
    }

    load(dst: Int) {
        throw BpfError("loading from empty slot")
    }

    store(src: Int) {
        throw BpfError("storing to empty slot")
    }

    load-addr(dst: Int) {
        throw BpfError("loading address of empty slot")
    }

    spill() -> Slot {
        throw BpfError("spilling empty slot")
    }

    zero() -> Any {
        throw BpfError("zeroing empty slot")
    }
}

class StackAllocator {
    __off:  Int
    __free: Array[(Int, Int, _)]
    __asm:  BpfAssembler

    init(off: Int = 0, asm: BpfAssembler) {
        __off  = off
        __free = []
        __asm  = asm
    }

    alloc(size: Int = 8) -> StackSlot {
        debug!(chalk"[bright green]alloc stack slot size {size} (off={__off})[/]")
        for (off, sz, _) in __free {
            debug!(chalk"[bright green]  free: @ {off} size {sz}[/]")
        }
        for i in ..#__free {
            let (off, sz, ctx) = __free[i]
            if sz >= size {
                __free.pop(i)
                if sz > size {
                    __free.push((off - size, sz - size, ctx))
                }
                __asm.note("reuse freed stack slot @ {off} size {size}")
                return StackSlot(off, size, self, __asm)
            }
        }

        __off += size

        __asm.note("alloc stack slot @ {__off} size {size}")
        StackSlot(__off, size, self, __asm)
    }

    free(slot: StackSlot) {
        if let $bad = __free.find(|(off, _, _)| -> off == slot.off) {
            throw BpfError("double free of stack slot @ {slot.off} size {slot.size}: {bad.2}")
        }
        __asm.note("free stack slot @ {slot.off} size {slot.size}")
        debug!(chalk"[bright green]free stack slot @ {slot.off} size {slot.size}[/]")
        __free.push((slot.off, slot.size, slot.ctx))
    }
}

pub class BpfProgram {
    __context:      BpfContext
    __type:         Int
    __tracing:      Array[EventHandle]
    __ast:          AST
    __asm:          BpfAssembler
    __fd:           Int
    __env:          Dict[String, Var]
    __var-off:      Int
    __fmts:         Array[Array[String | {type: BpfType | nil, fmt: String | nil}]]
    __strings:      Dict[String, Int]
    __scratch:      Var
    __output:       Var
    __zero:         Var
    __stacks:       Var
    __loop-depth:   Int
    __stack-alloc:  StackAllocator

    strings { __fmts }

    init(type: Int, ast: AST, context: BpfContext) {
        __context = context
        __type = type
        __ast = ast
        __asm = BpfAssembler()
        __fd = -1
        __tracing = []
        __env = %{}
        __loop-depth = 0
        __var-off = 16
        __fmts = []
        __strings = %{}

        __scratch = __var('__scratch')
        __scratch.type = UnknownPtr(U8)
        __scratch.map = map.Array(1, os.ncpu() * PER_CPU_SCRATCH)

        ringbuf('__output')
        __output = __var('__output')

        __zero = __var('__zero')
        __zero.map = map.PerCPUArray(1, 512)
        __zero.type = MapPtr(U8)

        __stacks = __var('__stacks')
        __stacks.map = context.stacks
        __stacks.type = StackMap

        __var('__dynptr', size=16)
        __var('cpu').type = U32

        __string('%s')
    }

    alloc(size: Int = 8) -> StackSlot {
        __stack-alloc.alloc(size)
    }

    __string(s: String) -> Int {
        if let $fd = __strings[s] {
            return fd
        }

        let attr = bpf_attr_map_create(
            map_type=BPF_MAP_TYPE_ARRAY,
            key_size=4,
            value_size=64,
            max_entries=1,
            map_flags=BPF_F_RDONLY_PROG
        )

        let fd = bpf(BPF_MAP_CREATE, attr)
        if fd < 0 {
            throw OSError('bpf(BPF_MAP_CREATE)')
        }

        let zero = c.box(c.u32, 0)

        let attr = bpf_attr_map_elem(
            map_fd=fd,
            key=zero,
            value=c.c_str(s),
            flags=BPF_ANY
        )

        let ret = bpf(BPF_MAP_UPDATE_ELEM, attr)
        if ret < 0 {
            throw OSError('bpf(BPF_MAP_UPDATE_ELEM)')
        }

        attr = bpf_attr_map_elem(map_fd=fd)
        ret = bpf(BPF_MAP_FREEZE, attr)
        if ret < 0 {
            throw OSError('bpf(BPF_MAP_FREEZE)')
        }

        __strings[s] = fd
    }

    __load-string(s: String, reg: Int) {
        let fd = __string(s)
        __asm.ld_map_value(reg, fd, 0)
    }

    __var(name: String, size: Int = 8) -> Var {
        if let $var = __env[name] {
            var
        } else {
            __var-off += size

            let var = Var(name, __var-off, self)

            if let $m = __context.maps[name] {
                var.type = match type(m) {
                    map.Array         => MapPtr(U8),
                    map.PerCPUArray   => I64,
                    map.Hash          => Hash(m.key-type, m.value-type),
                    map.RingBuffer    => RingBuffer,
                    _                 => throw BpfError("unsupported map type for global: {name}")
                }
                var.map = m
            } else if name.starts?('g_') {
                var.type = U64
                var.map  = __context.array(name)
            } else if name.starts?('t_') {
                var.type = U64
                var.map  = __context.per-cpu-array(name)
            }

            (__env[name] = var)
        }
    }

    __offset(name: String) -> Int {
        -__var(name).off
    }

    __load(slot: StackSlot, dst: Int) {
        let t = match slot.size {
            1 => U8,
            2 => U16,
            4 => U32,
            8 => U64,
            _ => throw BpfError("unsupported stack slot size: {slot.size}")
        }
        __load(rbp, -slot.off, t, dst)
    }

    __load(base: Int, off: Int, t: BpfType, dst: Int) {
        match t {
            U8  or I8  => __asm.ldx8(dst, base, off),
            U16 or I16 => __asm.ldx16(dst, base, off),
            U32 or I32 => __asm.ldx32(dst, base, off),
            U64 or I64 => __asm.ldx64(dst, base, off),
            AnyPtr(_)  => __asm.ldx64(dst, base, off),
            AnyMap     => __asm.ldx64(dst, base, off),
            Str(_) or Record(_) => do {
                __asm.mov64(dst, base);
                if off != 0 {
                    __asm.add64i(dst, off);
                }
            },
            _   => throw BpfError("unsupported type for load: {show(t)}")
        }
    }

    store(base: Int, off: Int, t: BpfType, src: Int) {
        __store(base, off, t, src)
    }

    __store(base: Int, off: Int, t: BpfType, src: Int) {
        match t {
            U8  or I8  => __asm.stx8(base, src, off),
            U16 or I16 => __asm.stx16(base, src, off),
            U32 or I32 => __asm.stx32(base, src, off),
            U64 or I64 => __asm.stx64(base, src, off),
            AnyPtr(_) or Str(_) or Record(_) => __asm.stx64(base, src, off),
            _   => throw BpfError("unsupported type for store: {t}")
        }
    }

    __store-var(var: String | Var, src: Int) {
        let var = (var :: String) ? __var(var) : var
        __asm.note("store var: {var.name} <- r{src}")
        if var.map :: map.PerCPUArray {
            let ^_k = alloc()
            let ^_v = alloc()

            __asm.imov64(r0, 0)
            _k.store(r0)

            _v.store(src)

            __asm.imov64(r4, 0)
            _v.load-addr(r3)
            _k.load-addr(r2)
            var.load(r1)

            __asm.call(helper.map_update_elem)
        } else if var.local? || var.map? {
            __store(rbp, -var.off, var.type, src)
        } else {
            let tmp = (src == r0) ? r1 : r0
            __load(rbp, -var.off, U64, tmp)
            __store(tmp, 0, var.type, src)
        }
    }

    __load-var(var: String | Var, dst: Int, deref?: Bool = true) -> Slot {
        let var = (var :: String) ? __var(var) : var
        __asm.note("load var: {deref? ? '' : '&'}{var.name} -> r{dst}")
        if var.map :: map.PerCPUArray {
            let ^_k = alloc()
            __asm.imov64(r0, 0)
            _k.store(r0)

            _k.load-addr(r2)
            var.load(r1)

            __asm.call(helper.map_lookup_elem)

            // NULL check
            let jump = __asm.jne64(r0, 0)
            __asm.exit()
            jump.patch()

            if deref? {
                __load(r0, 0, var.type, dst)
            } else {
                __asm.mov64(dst, r0)
            }
        } else if var.local? || var.map? {
            __load(rbp, -var.off, var.type, dst)
        } else if !deref? {
            __load(rbp, -var.off, U64, dst)
        } else {
            __load(rbp, -var.off, U64, dst)
            __load(r0, 0, var.type, dst)
        }
    }

    __jump-if(cond: AST) -> BpfJump {
        __jump-if-not(ty.Not(cond))
    }

    __jump-if-not(cond: AST) -> BpfJump {
        match cond {
            ty.Eq(a, ty.String(b)) => do {
                let n = match __analyze(a) {
                    StackPtr(I8, n) => n,
                    Str(n)          => n,
                    t0              => throw BpfError("bad comparison: {t0} == str")
                }
                let ^_a = __emit(a).spill()
                _a.load(r1)
                __asm.imov64(r2, n)
                __load-string(b, r3)
                __asm.call(helper.strncmp)
                __asm.jne64(r0, 0)
            },

            ty.Eq(a, b) => do {
                let ^_a = __emit(a).spill()
                let ^_b = __emit(b).spill()
                _a.load(r0)
                _b.load(r1)
                __asm.jne64x(r0, r1)
            },

            ty.NotEq(a, ty.String(b)) => do {
                let n = match __analyze(a) {
                    StackPtr(I8, n) => n,
                    Str(n)          => n,
                    t0              => throw BpfError("bad comparison: {t0} != str")
                }
                let ^_a = __emit(a).spill()
                _a.load(r1)
                __asm.imov64(r2, n)
                __load-string(b, r3)
                __asm.call(helper.strncmp)
                __asm.jeq64(r0, 0)
            },

            ty.GT(a, b) => do {
                let ^_a = __emit(a).spill()
                let ^_b = __emit(b).spill()
                _a.load(r0)
                _b.load(r1)
                __asm.jsle64x(r0, r1)
            },

            ty.LEQ(a, b) => do {
                let ^_a = __emit(a).spill()
                let ^_b = __emit(b).spill()
                _a.load(r0)
                _b.load(r1)
                __asm.jsgt64x(r0, r1)
            },

            ty.Not(x) => do {
                let jump1 = __jump-if-not(x)
                let jump2 = __asm.jmp64()
                jump1.patch()
                jump2
            },

            ty.And(a, b) => do {
                let jump1 = __jump-if-not(a)
                let jump2 = __jump-if-not(b)
                BpfJumpPair(jump1, jump2)
            },

            ty.Or(a, b) => do {
                let jump1 = __jump-if(a)
                let jump2 = __jump-if-not(b)
                jump1.patch()
                jump2
            },

            _ => do {
                let ^_cond = __emit(cond)
                _cond.load(r0)
                __asm.jeq64(r0, 0)
            }
        }
    }

    __enter-loop(max: Int = 512) -> Var {
        let var = __var("__loop{++__loop-depth}")
        __asm.imov64(r0, max)
        __store-var(var, r0)
        var
    }

    __check-loop(var: Var) {
        __load-var(var, r0)
        let jump = __asm.jle64(r0, 0)
        __asm.sub64i(r0, 1)
        __store-var(var, r0)
        jump
    }

    __exit-loop() {
        __loop-depth -= 1
    }

    __analyze-lvalue(lvalue: AST, t0: BpfType = nil) {
        match lvalue {
            ty.Id({name, ?constraint, *}) => {
                let var = __var(name)
                let typed? = (var.type != nil)

                let t1 = (constraint != nil) ?: ty-to-bpf(constraint)

                var.type = var.type ?? match (t0, t1) {
                    (nil, nil) => throw BpfError("cannot infer type of `{name}`"),
                    (nil, $t)  => t,
                    ($t, nil)  => t,
                    ($t, t)    => t,
                    (AnyInt, Const(_))     => t0,
                    (Const(_), AnyInt)     => t1,
                    (AnyPtr(_), AnyPtr(_)) => t0,
                    (
                        AnyInt or AnyPtr(_),
                        AnyInt or AnyPtr(_)
                    ) => t1,
                    (t0, t1)   => throw BpfError("type mismatch for variable `{name}`: {t0} vs {t1}")
                }

                if let Const(_) = var.type {
                    var.type = U64
                }

                if !typed? {
                    match var.type {
                        Hash(k0, v0) => {
                            var.map = __context.hash(
                                name,
                                key-type=deref-ptr-type(k0),
                                value-type=deref-ptr-type(v0),
                                max-buckets=1024
                            )
                        },

                        _ => {}
                    }
                }

                var.type
            },

            ty.Array([ty.ArrayItem({item, *})]) => {
                let t0 = __analyze(item)
                match t0 {
                    AnyPtr(t) => t,
                    _         => { pp(t0); throw BpfError("attempt to dereference non-pointer type: {t0}") }
                }
            },

            ty.Subscript(target, index) => {
                let t1 = __analyze(index)
                let t2 = __analyze-lvalue(target, Hash(deref-ptr-type(t1), deref-ptr-type(t0)))
                debug!({lvalue, t1, t2})
                t2
            },

            ty.Record(fields) => {
                let types = match t0 {
                    AnyPtr(Record(ts)) => ts,
                    Record(ts)         => ts,
                    _                  => throw BpfError("cannot index into non-record type: {t0}")
                }
                for ty.RecordEntry({item, *}), i in fields {
                    __analyze-lvalue(item, types[i])
                }
                t0
            },

            _ => throw BpfError("invalid lvalue: {show(lvalue)}")
        }
    }

    __int-promote(t0: BpfType, t1: BpfType) -> BpfType {
        match (signed?(t0) || signed?(t1), max(size-of(t0), size-of(t1))) {
            (true,  8) => I64,
            (true,  4) => I32,
            (true,  2) => I16,
            (true,  1) => I8,
            (false, 8) => U64,
            (false, 4) => U32,
            (false, 2) => U16,
            (false, 1) => U8,
        }
    }

    __analyze(expr: AST) -> BpfType {
        match expr {
            ty.Id({name, *}) => {
                __var(name).type
            },

            ty.Int(k) => {
                Const(k)
            },

            ty.String(s) => {
                MapPtr(I8)
            },

            ty.Cast(a, b) => {
                let t0 = ty-to-bpf(b)
                __analyze(a)
                t0
            },

            ty.Let(target, value) or ty.Assign(target, value) => {
                let t0 = __analyze(value)
                __analyze-lvalue(target, t0)
            },

            ty.Multi(stmts) => {
                for stmts {
                    __analyze(it)
                }
                Unit
            },

            ty.Block(stmts) => {
                for stmts {
                    __analyze(it)
                }
                Unit
            },

            ty.Call({func: ty.Id({name, *}), args, *}) => {
                let arg-types = args.map(match {
                    ty.Arg({arg: value, *}) => __analyze(value),
                    ty.Spread(value)        => __analyze(value)
                })

                match name {
                    'now'    => I64,
                    'tai'    => Time64,
                    'print'  => Unit,
                    'hist'   => Histogram,
                    'sum'    => U64,
                    'len'    => U64,
                    'ustack' => do {
                        __var('__pidq')
                        __var('__pids')
                        UStack
                    },
                    'kstack' => do {
                        KStack
                    },
                    'exit' => nil,
                    'str'  => match arg-types {
                        [_, Const(n)] => Str(n),
                        [_]           => UserPtr(I8),
                        _             => throw BpfError("invalid arguments to str()")
                    },
                    _       => throw BpfError("unknown function: {name}")
                }
            },

            ty.If([cond], then, otherwise) => {
                __analyze(cond)
                let t0 = __analyze(then)
                if otherwise != nil {
                    __analyze(otherwise)
                }
                t0
            },

            ty.Cond(cond, then, otherwise) => {
                __analyze(cond)
                let t0 = __analyze(then)
                if otherwise != nil {
                    __analyze(otherwise)
                }
                t0
            },

            ty.While([cond], body) => {
                __loop-depth += 1
                __var("__loop{__loop-depth}").type = U16
                __analyze(cond)
                __analyze(body)
                __loop-depth -= 1
                Unit
            },

            ty.Add(a, b) => {
                let t0 = __analyze(a)
                let t1 = __analyze(b)
                match (t0, t1) {
                    (Const(a), Const(b))       => Const(a + b),
                    (StackPtr(t, n), Const(k)) => StackPtr(t, n + k),
                    (AnyInt, AnyInt)           => __int-promote(t0, t1),
                    (AnyPtr(_), AnyInt)        => t0,
                    _ => throw BpfError("unsupported types for Add: {t0}, {t1}")
                }
            },

            ty.Sub(a, b) => {
                let t0 = __analyze(a)
                let t1 = __analyze(b)
                match (t0, t1) {
                    (Const(a), Const(b))       => Const(a - b),
                    (StackPtr(t, n), Const(k)) => StackPtr(t, n - k),
                    (AnyInt, AnyInt)           => __int-promote(t0, t1),
                    (AnyPtr(_), AnyInt)        => t0,
                    _ => throw BpfError("unsupported types for Sub: {t0}, {t1}")
                }
            },

            ty.Mul(a, b) => {
                let t0 = __analyze(a)
                let t1 = __analyze(b)
                match (t0, t1) {
                    (Const(a), Const(b)) => Const(a * b),
                    (AnyInt, AnyInt)     => __int-promote(t0, t1),
                    _ => throw BpfError("unsupported types for Mul: {t0}, {t1}"),
                }
            },

            ty.Div(a, b) => {
                let t0 = __analyze(a)
                let t1 = __analyze(b)
                match (t0, t1) {
                    (Const(a), Const(b)) => Const(a / b),
                    (AnyInt, AnyInt)     => __int-promote(t0, t1)
                    _ => throw BpfError("unsupported types for Div: {t0}, {t1}"),
                }
            },

            ty.BitAnd(a, b) => {
                let t0 = __analyze(a)
                let t1 = __analyze(b)
                match (t0, t1) {
                    (Const(a), Const(b)) => Const(a & b),
                    (AnyInt, AnyInt)     => __int-promote(t0, t1),
                    _ => throw BpfError("unsupported types for BitAnd: {t0}, {t1}")
                }
            },

            ty.BitOr(a, b) => {
                let t0 = __analyze(a)
                let t1 = __analyze(b)
                match (t0, t1) {
                    (Const(a), Const(b)) => Const(a | b),
                    (AnyInt, AnyInt)     => __int-promote(t0, t1),
                    _ => throw BpfError("unsupported types for BitOr: {t0}, {t1}")
                }
            },

            ty.Array([ty.ArrayItem({item, *})]) => {
                let t0 = __analyze(item)
                match t0 {
                    AnyPtr(t) => t,
                    _         => throw BpfError("attempt to dereference non-pointer type: {t0}")
                }
            },

            ty.Record(items) => {
                Record([__analyze(item) for ty.RecordEntry({item, *}) in items])
            },

            ty.Subscript(xs, idx) => {
                let t0 = __analyze(xs)
                let t1 = __analyze(idx)
                match (t0, t1) {
                    (Hash(_, Str(n)), _) => MapPtr(Str(n)),
                    (Hash(_, Record(fields)), _) => MapPtr(Record(fields)),
                    (Hash(_, v0), _) => v0
                    (Record(fields) or AnyPtr(Record(fields)), Const(i)) => do {
                        if i < 0 || i >= #fields {
                            throw BpfError("record index out of bounds: {i}")
                        }
                        fields[i]
                    },
                    (AnyPtr(t), AnyInt or Const(_)) => t,
                    _ => throw BpfError("unsupported types for Subscript: {t0}, {t1}")
                }
            },

            ty.MemberAccess(target, member) => {
                let t0 = __analyze(target)
                match t0 {
                    AnyPtr(Struct(fields)) => do {
                        if let (off, bpf-type) = fields[member] {
                            bpf-type
                        } else {
                            throw BpfError("unknown struct member: {member}")
                        }
                    },

                    _ => throw BpfError("unsupported type for MemberAccess: {t0}")
                }
            },

            ty.SpecialString(parts) => {
                for match parts {
                    ($expr, _, _, _) => __analyze(expr),
                    _                => ()
                }
                nil
            },

            ty.Eq(a, b),
            ty.LT(a, b),
            ty.GT(a, b),
            ty.LEQ(a, b),
            ty.GEQ(a, b),
            ty.NotEq(a, b),
            ty.And(a, b),
            ty.Or(a, b) => {
                __analyze(a)
                __analyze(b)
                U64
            },

            ty.In(x, xs) => {
                __analyze(x)
                __analyze(xs)
                U64
            },

            ty.Not(x) => {
                __analyze(x)
                U64
            },

            _ => throw BpfError("unsupported expression: {show(expr)}"),
        }
    }

    __bop64(op: _, a: AST, b: AST) -> Slot {
        let ^_a = __emit(a).spill()
        let ^_b = __emit(b).spill()

        _a.load(r0)
        _b.load(r1)

        op(r0, r1)

        RegZeroSlot(self)
    }

    __reg(*used: Int) -> Int {
        for r in r0...r8 {
            if r not in used {
                return r
            }
        }
        throw BpfError("ran out of registers")
    }

    __log2(dst: Int, src: Int) {
        let arg = __reg(src, dst)
        let tmp = __reg(src, dst, arg)
        __asm.mov64(arg, src)
        __asm.imov64(dst, 0)
        __asm.mov64(tmp, arg)
        __asm.and64i(tmp, 0xFFFFFFFF00000000)
        let j1 = __asm.jeq64(tmp, 0)
        __asm.add64i(dst, 32)
        __asm.shr64i(arg, 32)
        j1.patch()
        __asm.mov64(tmp, arg)
        __asm.and64i(tmp, 0xFFFF0000)
        let j2 = __asm.jeq64(tmp, 0)
        __asm.add64i(dst, 16)
        __asm.shr64i(arg, 16)
        j2.patch()
        __asm.mov64(tmp, arg)
        __asm.and64i(tmp, 0xFF00)
        let j3 = __asm.jeq64(tmp, 0)
        __asm.add64i(dst, 8)
        __asm.shr64i(arg, 8)
        j3.patch()
        __asm.mov64(tmp, arg)
        __asm.and64i(tmp, 0xF0)
        let j4 = __asm.jeq64(tmp, 0)
        __asm.add64i(dst, 4)
        __asm.shr64i(arg, 4)
        j4.patch()
        __asm.mov64(tmp, arg)
        __asm.and64i(tmp, 0xC)
        let j5 = __asm.jeq64(tmp, 0)
        __asm.add64i(dst, 2)
        __asm.shr64i(arg, 2)
        j5.patch()
        __asm.mov64(tmp, arg)
        __asm.and64i(tmp, 0x2)
        let j6 = __asm.jeq64(tmp, 0)
        __asm.add64i(dst, 1)
        j6.patch()
    }

    __load-key(k: Slot, k0: BpfType, sz: Int) -> Slot | nil {
        let key = nil

        match k0 {
            Str(n) or AnyPtr(Str(n)) => do {
                key = alloc(sz)
                key.zero()
                k.load(r3)
                __asm.imov64(r2, n)
                key.load-addr(r1)
                __asm.call(helper.probe_read_str)
                key.load-addr(r0)
            },
            UserPtr(t0) or KernelPtr(t0) or UnknownPtr(t0) => do {
                key = alloc(sz)
                k.load(r3)
                __asm.imov64(r2, 8)
                key.load-addr(r1)
                __asm.call(match t0 {
                    I8 => helper.probe_read_str,
                    _  => helper.probe_read
                })
                key.load-addr(r0)
            },
            AnyPtr(_) or Str(_) => k.load(r0),
            _                   => k.load-addr(r0)
        }

        key
    }

    __hash-lookup(xs: Slot, idx: Slot, k0: BpfType, sz: Int) {
        xs.load(r6)
        let ^_ = __load-key(idx, k0, sz)
        __asm.mov64(r1, r6)
        __asm.mov64(r2, r0)
        __asm.call(helper.map_lookup_elem)
    }


    __load-val(_v: Slot, v0: BpfType, t: BpfType) {
        let _tmp = nil

        match v0 {
            Str(n) or AnyPtr(Str(n)) => do {
                _tmp = alloc(n)
                _tmp.zero()
                __asm.mov64(r7, r2)

                _v.load(r3)
                __asm.imov64(r2, n)
                _tmp.load-addr(r1)
                __asm.call(helper.probe_read_str)
                _tmp.load-addr(r3)

                __asm.mov64(r2, r7)
            },

            UserPtr(t0) or KernelPtr(t0) or UnknownPtr(t0) => do {
                _tmp = alloc(size-of(t))
                __asm.mov64(r7, r2)

                _v.load(r3)
                __asm.imov64(r2, size-of(t))
                _tmp.load-addr(r1)
                __asm.call(match t {
                    I8 => helper.probe_read_str,
                    _  => helper.probe_read
                })
                _tmp.load-addr(r3)

                __asm.mov64(r2, r7)
            },

            _ => do {
                _v.load-addr(r3)
            }
        }

        _tmp
    }

    __emit(expr: AST) -> Slot {
        catch error: BpfError {
            pp(expr)
            eprint("{error}\n{error.trace()}")
            eprint("Context: {parse.show(expr)}")
            exit(1)
        }
        match expr {
            ty.Id({name, *}) => {
                __load-var(name, r0)
                RegZeroSlot(self)
            },

            ty.Int(k) => {
                __asm.imov64(r0, k)
                RegZeroSlot(self)
            },

            ty.String(s) => {
                __load-string(s, r0)
                RegZeroSlot(self)
            },

            ty.Add(a, b)    => __bop64(__asm.add64, a, b),
            ty.Sub(a, b)    => __bop64(__asm.sub64, a, b),
            ty.Mul(a, b)    => __bop64(__asm.mul64, a, b),
            ty.Div(a, b)    => __bop64(__asm.div64, a, b),
            ty.BitAnd(a, b) => __bop64(__asm.and64, a, b),
            ty.BitOr(a, b)  => __bop64(__asm.or64, a, b),

            ty.Cast(a, _) => {
                __emit(a)
            },

            ty.Eq(a, b) => {
                let ^_a = __emit(a).spill()
                let ^_b = __emit(b).spill()

                _a.load(r0)
                _b.load(r1)

                let jump = __asm.jeq64x(r0, r1)
                __asm.imov64(r0, 0)
                let end = __asm.jmp64()
                jump.patch()
                __asm.imov64(r0, 1)
                end.patch()

                RegZeroSlot(self)
            },

            ty.Call({func: ty.Id({name, *}), args, *}) => {
                match name {
                    'exit' => {
                        match args {
                            [ty.Arg({arg, *})] => {
                                let ^_arg = __emit(arg)
                                _arg.load(r0)
                                __asm.exit()
                            },

                            _ => throw BpfError('exit() expects one argument')
                        }
                    },

                    'now' => {
                        match args {
                            [] => {
                                __asm.call(helper.ktime_get_ns)
                                RegZeroSlot(self)
                            },

                            _ => throw BpfError('now() expects no arguments')
                        }
                    },

                    'tai' => {
                        match args {
                            [] => {
                                __asm.call(helper.ktime_get_tai_ns)
                                RegZeroSlot(self)
                            },

                            _ => throw BpfError('now() expects no arguments')
                        }
                    },

                    'print' => {
                        match args {
                            [ty.Arg({arg, *})] => {
                                __emit(arg)
                            },

                            _ => throw BpfError('print() expects one argument')
                        }
                    },

                    'str' => {
                        match args {
                            [ty.Arg({arg, *}), *] => __emit(arg)
                        }
                    },

                    'kstack' => {
                        match args {
                            [] => {
                                __load-var('ctx', r1)
                                __load-var('__stacks', r2)
                                __asm.imov64(r3, BPF_F_REUSE_STACKID)
                                __asm.call(helper.get_stackid)

                                __load-var('tgid', r1)
                                __asm.shl64i(r0, 32)
                                __asm.or64(r0, r1)

                                RegZeroSlot(self)
                            },

                            _ => throw BpfError('kstack() expects no arguments')
                        }
                    },

                    'ustack' => {
                        match args {
                            [] => {
                                // Check if we should notify userland
                                __asm.call(helper.ktime_get_ns)
                                __asm.mov64(r6, r0)

                                __var('tgid').load-addr(r7)

                                __load-var('__pids', r1)
                                __asm.mov64(r2, r7)
                                __asm.call(helper.map_lookup_elem)

                                let absent = __asm.jeq64(r0, 0)
                                __asm.ldx64(r1, r0)
                                __asm.mov64(r2, r6)
                                __asm.sub64(r2, r1)
                                __asm.ld64(r5, 500_000_000)
                                let skip = __asm.jle64x(r2, r5)
                                __asm.stx64(r0, r6, 0)
                                let updated = __asm.jmp64()
                                absent.patch()
                                let ^tmp = alloc()
                                tmp.store(r6)
                                __load-var('__pids', r1)
                                __asm.mov64(r2, r7)
                                tmp.load-addr(r3)
                                __asm.imov64(r4, BPF_ANY)
                                __asm.call(helper.map_update_elem)
                                updated.patch()
                                __load-var('__pidq', r1)
                                __var('tgid').load-addr(r2)
                                __asm.imov64(r3, 4)
                                __asm.imov64(r4, BPF_RB_FORCE_WAKEUP)
                                __asm.call(helper.ringbuf_output)
                                skip.patch()

                                __load-var('ctx', r1)
                                __load-var('__stacks', r2)
                                __asm.imov64(r3, BPF_F_USER_STACK | BPF_F_REUSE_STACKID)
                                __asm.call(helper.get_stackid)

                                __load-var('tgid', r1)
                                __asm.shl64i(r0, 32)
                                __asm.or64(r0, r1)

                                RegZeroSlot(self)
                            },

                            _ => throw BpfError('ustack() expects no arguments')
                        }
                    },

                    'len' => {
                        match args {
                            [ty.Arg({arg, *})] => {
                                let ^_arg = __emit(arg).spill()
                                match __analyze(arg) {
                                    StringLike => {
                                        __asm.imov64(r5, 8)
                                        _arg.load-addr(r4)
                                        __load-string('%s', r3)
                                        __asm.imov64(r2, 0)
                                        __scratch.load-addr(r1)
                                        __asm.call(helper.snprintf)
                                        RegZeroSlot(self)
                                    },

                                    _ => throw BpfError('len() argument must be a string or string-like type')
                                }
                            },

                            _ => throw BpfError('len() expects one argument')
                        }
                    },

                    _ => throw BpfError("unknown function: {name}"),
                }
            },

            ty.Assign(
                ty.Subscript(xs, idx),
                ty.Call({
                    func: ty.Id({name: 'sum', *}),
                    args: [ty.Arg({arg: value, *})],
                    *
                })
            ) => {
                let xs0  = __analyze(xs)
                let idx0 = __analyze(idx)

                let sz = match xs0 {
                    Hash(k0, _) => size-of(k0),
                    _           => throw BpfError('sum() target must be a hash map')
                }

                let ^_idx = __emit(idx).spill()
                let ^_xs  = __emit(xs).spill()

                __asm.note('load xs into r1')
                _xs.load(r1)
                let ^_ = __load-key(_idx, idx0, sz)
                __asm.mov64(r7, r0)

                // Ensure counter exists
                __load-var('__zero', r3, deref?=false)
                __asm.note('load xs into r1')
                _xs.load(r1)
                __asm.mov64(r2, r7)
                __asm.imov64(r4, BPF_NOEXIST)
                __asm.call(helper.map_update_elem)

                // Lookup pointer to counter
                _xs.load(r1)
                __asm.mov64(r2, r7)
                __asm.call(helper.map_lookup_elem)

                // NULL check
                let jump = __asm.jne64(r0, 0)
                __asm.exit()
                jump.patch()

                // Keep counter pointer in r8 for now
                __asm.mov64(r8, r0)

                let ^_arg = __emit(value).spill()
                _arg.load(r4)

                __asm.mov64(r0, r8)
                __asm.imov64(r2, 0)
                __asm.imul64i(r2, 8)
                __asm.add64(r0, r2)
                __asm.fetch-add(r0, r4)
                __asm.mov64(r0, r4)

                RegZeroSlot(self)
            },

            ty.Assign(
                ty.Subscript(xs, idx),
                ty.Call({
                    func: ty.Id({name: 'hist', *}),
                    args: [ty.Arg({arg: value, *})],
                    *
                })
            ) => {
                let xs0  = __analyze(xs)
                let idx0 = __analyze(idx)

                let sz = match xs0 {
                    Hash(k0, _) => size-of(k0),
                    _           => throw BpfError("hist() target must be a hash map")
                }

                let ^_idx = __emit(idx).spill()
                let ^_xs  = __emit(xs).spill()

                let ^_ = __load-key(_idx, idx0, sz)
                __asm.mov64(r7, r0) // Save key in r7

                // Ensure histogram exists
                __load-var('__zero', r3, deref?=false)
                _xs.load(r1)
                __asm.mov64(r2, r7)
                __asm.imov64(r4, BPF_NOEXIST)
                __asm.call(helper.map_update_elem)

                // Lookup pointer to histogram
                _xs.load(r1)
                __asm.mov64(r2, r7)
                __asm.call(helper.map_lookup_elem)

                // NULL check
                let jump = __asm.jne64(r0, 0)
                __asm.exit()
                jump.patch()

                // Keep histogram pointer in r8 for now
                __asm.mov64(r8, r0)

                let ^_arg = __emit(value).spill()
                _arg.load(r0)
                __log2(r1, r0)

                // Now r1 has the bucket index. Compute address of counter and increment it.
                __asm.mov64(r0, r8)
                __asm.imov64(r2, 0)
                __asm.imul64i(r1, 8)
                __asm.add64(r0, r1)
                __asm.imov64(r1, 1)
                __asm.fetch-add(r0, r1)
                __asm.mov64(r0, r1)

                RegZeroSlot(self)
            },

            ty.Assign(
                ty.Id({name: hist, *}),
                ty.Call({
                    func: ty.Id({name: 'hist', *}),
                    args: [ty.Arg({arg: value, *})],
                    *
                })
            ) => {
                let ^_arg = __emit(value).spill()
                __load-var(hist, r7, deref?=false)

                _arg.load(r0)
                __log2(r1, r0)

                __asm.mov64(r0, r7)
                __asm.imov64(r2, 0)
                __asm.imul64i(r1, 8)
                __asm.add64(r0, r1)
                __asm.imov64(r1, 1)
                __asm.fetch-add(r0, r1)
                __asm.mov64(r0, r1)

                RegZeroSlot(self)
            }

            ty.Let(target, value),
            ty.Assign(target, value) => {
                let ^_v = __emit(value)
                match target {
                    ty.Id({name, *}) => {
                        _v.load(r0)
                        __store-var(name, r0)
                        RegZeroSlot(self)
                    },

                    ty.Array([ty.ArrayItem({item, *})]) => {
                        _v = _v.spill()
                        let ^_p = __emit(item).spill()
                        _v.load(r0)
                        _p.load(r1)
                        __store(r1, 0, __analyze-lvalue(item) ?? __analyze(value), r0)
                    },

                    ty.Subscript(xs, idx) => {
                        _v = _v.spill()

                        let ^_i  = __emit(idx).spill()
                        let ^_xs = __emit(xs).spill()

                        _xs.load(r1)

                        match __analyze(xs) {
                            AnyPtr(t) => {
                                _v.load(r2)
                                _i.load(r0)
                                __asm.imul64i(r0, size-of(t))
                                __asm.add64(r1, r0)
                                __store(r1, 0, t, r0)
                                RegZeroSlot(self)
                            },

                            Hash(k0, t) => {
                                let sz = size-of(k0)

                                __asm.mov64(r8, r1)

                                let ^_ = __load-key(_i, __analyze(idx), sz)
                                __asm.mov64(r2, r0)

                                let ^_ = __load-val(_v, __analyze(value), t)

                                __asm.mov64(r1, r8)
                                __asm.imov64(r4, 0)
                                __asm.call(helper.map_update_elem)
                            },

                            _ => throw BpfError("unsupported type for subscript assignment")
                        }
                    },

                    _ => throw BpfError("invalid assignment target")
                }

                EmptySlot()
            },

            ty.Multi(stmts) => {
                for stmts {
                    __emit(it)
                }
                EmptySlot()
            },

            ty.Block(stmts) => {
                for stmts {
                    __emit(it)
                }
                EmptySlot()
            },

            ty.If((
                [ty.Let(ty.Record(lhs), rhs)],
                then,
                ?otherwise
            )) => {
                let lhs = [item for ty.RecordEntry({item, *}) in lhs]
                let t0 = __analyze(rhs)
                if not let AnyPtr(Record(fields)) = t0 {
                    throw BpfError("expected record type in destructuring let")
                }

                let ^_rhs = __emit(rhs).spill()

                _rhs.load(r0)
                let null = __asm.jeq64(r0, 0)

                let offset = 0
                for i in ..#lhs {
                    let ^_field = alloc(size-of(fields[i]))
                    __asm.note("load record field {i} at offset {offset}: {fields[i]}")
                    _rhs.load(r3)
                    __load(r3, offset, fields[i], r0)
                    _field.store(r0)
                    __asm.note("------------")

                    match lhs[i] {
                        ty.Id({name, *}) => {
                            _field.load(r0)
                            __store-var(name, r0)
                        },

                        _ => throw BpfError("invalid assignment target in destructuring let")
                    }

                    offset += align(size-of(fields[i]))
                }

                let ^_ = __emit(then)

                if otherwise != nil {
                    let end = __asm.jmp64()
                    null.patch()
                    let ^_ = __emit(otherwise)
                    end.patch()
                } else {
                    null.patch()
                }

                EmptySlot()
            }

            ty.If([cond], then, otherwise),
            ty.Cond(cond, then, otherwise) => {
                let jump = __jump-if-not(cond)
                let ^_ = __emit(then)
                if otherwise != nil {
                    let end = __asm.jmp64()
                    jump.patch()
                    let ^_ = __emit(otherwise)
                    end.patch()
                } else {
                    jump.patch()
                }
                EmptySlot()
            },

            ty.While([cond], body) => {
                let limit = __enter-loop()
                let start = __asm.label()

                let jump = match cond {
                    ty.Eq(a, b) => do {
                        let ^_a = __emit(a).spill()
                        let ^_b = __emit(b).spill()
                        _a.load(r0)
                        _b.load(r1)
                        __asm.jne64x(r0, r1)
                    },

                    ty.NotEq(a, b) => do {
                        let ^_a = __emit(a).spill()
                        let ^_b = __emit(b).spill()
                        _a.load(r0)
                        _b.load(r1)
                        __asm.jeq64x(r0, r1)
                    },

                    ty.Not(x) => do {
                        let ^_x = __emit(x)
                        _x.load(r0)
                        __asm.jne64(r0, 0)
                    },

                    _ => do {
                        let ^_cond = __emit(cond)
                        _cond.load(r0)
                        __asm.jeq64(r0, 0)
                    }
                }

                let abort = __check-loop(limit)
                let ^_ = __emit(body)
                __asm.jmp64(to=start)
                jump.patch()
                abort.patch()

                __exit-loop()

                EmptySlot()
            },

            ty.MemberAccess(target, member) as field => {
                let t0 = __analyze(field)
                let ^_target = __emit(target)

                match __analyze(target) {
                    UserPtr(Struct(fields)) => do {
                        let tmp = alloc(size-of(t0))
                        _target.load(r3)
                        __asm.imov64(r2, size-of(t0))
                        tmp.load-addr(r1)
                        __asm.call(helper.probe_read_user)
                        tmp
                    },

                    AnyPtr(Struct(fields)) => do {
                        _target.load(r1)
                        if let (off, bpf-type) = fields[member] {
                            __load(r1, off, bpf-type, r0)
                            RegZeroSlot(self)
                        } else {
                            throw BpfError("unknown struct member: {member}")
                        }
                    },

                    t0 => throw BpfError("unsupported type for MemberAccess: {t0}")
                }
            },

            ty.Record(items) => {
                let items = [item for ty.RecordEntry({item, *}) in items]
                let types = [__analyze(item) for item in items]

                let slot = alloc(size-of(Record(types)))
                slot.zero()

                let offset = 0

                for i in ..#items {
                    let ^_item = __emit(items[i]).spill()
                    _item.copy-into-stack(-slot.off + offset, types[i])
                    offset += align(size-of(types[i]))
                }

                slot
            },

            ty.Array([ty.ArrayItem({item, *})]) => {
                let ^_item = __emit(item)
                match __analyze(item) {
                    MapPtr(t0) or StackPtr(t0, _) => do {
                        _item.load(r1)
                        __load(r1, 0, t0, r0)
                        RegZeroSlot(self)
                    },

                    KernelPtr(t0) or UserPtr(t0) => do {
                        let sz = size-of(t0)
                        let _out = alloc(sz)
                        _item.load(r3)
                        __asm.imov64(r2, sz)
                        _out.load-addr(r1)
                        __asm.call(helper.probe_read)
                        _out
                    },

                    t0 => { pp(t0); throw BpfError("attempt to dereference non-pointer type: {t0}") }
                }
            },

            ty.SpecialString(parts) => {
                let to-send = []
                let total-size = 0

                __asm.imov64(r9, 0) // dynamic size counter

                let parts = parts.reverse()
                let (_, _, id, _) = parts.pop()!

                for part, i in parts {
                    let i = #parts - i - 1
                    match part {
                        (expr, _, _, _) => do {
                            let t0 = __analyze(expr)
                            let _fmt = __fmts[id][2*i + 1]

                            match t0 {
                                AnyMap => do {
                                    if not let ty.Id({name, *}) = expr {
                                        throw BpfError("compound expression with map type in string")
                                    }
                                    _fmt.type = MapRef(__var(name).map)
                                    continue
                                },

                                _ => do {
                                    _fmt.type = t0
                                }
                            }

                            let slot = __emit(expr).spill()
                            if matches?(t0, StringLike) {
                                // string pointer
                                __asm.imov64(r5, 8)
                                slot.load-addr(r4)

                                __load-string('%s', r3)

                                __asm.imov64(r2, 0)

                                // dummy buffer in stack
                                __asm.mov64(r1, rbp)
                                __asm.add64i(r1, -8)

                                __asm.call(helper.snprintf)

                                // add to total size
                                __asm.add64(r9, r0)
                            }

                            to-send.push((t0, slot))
                        },

                        _ => ()
                    }
                }

                let total-size = to-send.map(size-of . &0).sum() ?? 0

                // Set up dynptr address in r7
                __asm.mov64(r7, rbp)
                __asm.add64i(r7, __offset('__dynptr'))

                __load-var('__output', r1)
                __asm.imov64(r2, total-size + 12)
                __asm.add64(r2, r9)
                __asm.imov64(r3, 0)
                __asm.mov64(r4, r7)
                __asm.call(helper.ringbuf_reserve_dynptr)

                // Success check
                let jump = __asm.jeq64(r0, 0)
                __asm.imov64(r2, 0)
                __asm.mov64(r1, r7)
                __asm.call(helper.ringbuf_discard_dynptr)
                __asm.imov64(r0, 1)
                __asm.exit()
                jump.patch()

                // Push ID
                let ^_tmp = alloc()
                __asm.imov64(r0, id)
                _tmp.store(r0)

                // dynptr_write() ID at offset 0
                __asm.imov64(r5, 0)
                __asm.imov64(r4, 4)
                _tmp.load-addr(r3)
                __asm.imov64(r2, 0)
                __asm.mov64(r1, r7)
                __asm.call(helper.dynptr_write)

                // dynptr_write() tgid_pid at offset 4
                __asm.imov64(r5, 0)
                __asm.imov64(r4, 8)

                __var('tgid').load(r3)
                __asm.shl64i(r3, 32)
                __var('cpu').load(r0)
                __asm.or64(r3, r0)
                _tmp.store(r3)
                _tmp.load-addr(r3)

                __asm.imov64(r2, 4)
                __asm.mov64(r1, r7)
                __asm.call(helper.dynptr_write)

                // r6 = current offset in dynptr
                __asm.imov64(r6, 12)

                // r8 = scratch pointer w/ per-CPU offset
                __load-var('__scratch', r8, deref?=false)
                __load-var('cpu', r0)
                __asm.imul64i(r0, PER_CPU_SCRATCH)
                __asm.add64(r8, r0)

                for (t, ^slot) in to-send.reverse() {
                    match t {
                        StringLike => {
                            __asm.mov64(r1, r8)
                            __asm.imov64(r2, PER_CPU_SCRATCH)
                            slot.load(r3)
                            __asm.call(helper.probe_read_str)

                            // flags
                            __asm.imov64(r5, 0)

                            // length
                            __asm.mov64(r4, r0)
                            __asm.and64i(r4, PER_CPU_SCRATCH - 1)

                            // map ptr
                            __asm.mov64(r3, r8)

                            // offset
                            __asm.mov64(r2, r6)

                            // dynptr address
                            __asm.mov64(r1, r7)

                            // advance offset
                            __asm.add64(r6, r4)

                            __asm.call(helper.dynptr_write)
                        },

                        _ => {
                            let sz = size-of(t)

                            let (mov, store) = match sz {
                                1 => (__asm.mov8,  __asm.stx8),
                                2 => (__asm.mov16, __asm.stx16),
                                4 => (__asm.mov32, __asm.stx32),
                                8 => (__asm.mov64, __asm.stx64),
                                _ => throw BpfError("unsupported size for special string part: {sz}")
                            }

                            slot.load(r0)
                            mov(r0, r0)
                            with _tmp = alloc(sz) {
                                _tmp.store(r0)
                                __asm.imov64(r5, 0)
                                __asm.imov64(r4, sz)
                                _tmp.load-addr(r3)
                                __asm.mov64(r2, r6)
                                __asm.mov64(r1, r7)
                                __asm.call(helper.dynptr_write)

                                __asm.add64i(r6, sz)
                            }
                        }
                    }
                }

                __asm.mov64(r1, r7)
                __asm.imov64(r2, 0)
                __asm.call(helper.ringbuf_submit_dynptr)

                EmptySlot()
            },

            ty.Subscript(xs, idx) => {
                let ^_i  = __emit(idx).spill()
                let ^_xs = __emit(xs).spill()

                _xs.load(r0)

                match __analyze(xs) {
                    Record(fields) or AnyPtr(Record(fields)) => do {
                        let i = match __analyze(idx) {
                            Const(i) => i,
                            _        => throw BpfError("record subscript must be a constant integer")
                        }
                        if i < 0 || i >= #fields {
                            throw BpfError("record index out of bounds: {i}")
                        }
                        let off = fields[;i].map(t -> align(size-of(t))).sum(0)
                        __asm.note("load record field {i} at offset {off}")
                        __load(r0, off, fields[i], r0)
                        RegZeroSlot(self)
                    },

                    MapPtr(t) or StackPtr(t, _) => do {
                        let sz = size-of(t)
                        _i.load(r1)
                        __asm.imov64(r2, sz)
                        __asm.mul64(r1, r2)
                        __asm.add64(r0, r1)
                        __load(r0, 0, t, r0)
                        RegZeroSlot(self)
                    },

                    UserPtr(t) or KernelPtr(t) => do {
                        let sz = size-of(t)
                        _i.load(r1)
                        __asm.imul64i(r1, sz)
                        __asm.add64(r0, r1)

                        __asm.mov64(r3, r0)
                        __asm.imov64(r2, sz)

                        let out = alloc(sz)
                        out.load-addr(r1)

                        __asm.call(helper.probe_read)

                        out
                    },

                    Hash(k0, t) => do {
                        let sz = size-of(k0)
                        let ^_tmp = nil

                        __asm.mov64(r8, r0)

                        match __analyze(idx) {
                            UserPtr(t0) or KernelPtr(t0) or UnknownPtr(t0) => {
                                _tmp = alloc(sz)
                                _i.load(r3)
                                __asm.imov64(r2, sz)
                                _tmp.load-addr(r1)
                                __asm.call(match t0 {
                                    I8 => helper.probe_read_str,
                                    _  => helper.probe_read
                                })
                                _tmp.load-addr(r2)
                            },
                            AnyPtr(_) => _i.load(r2),
                            _         => _i.load-addr(r2)
                        }

                        __asm.mov64(r1, r8)
                        __asm.call(helper.map_lookup_elem)

                        let jump = __asm.jeq64(r0, 0)
                        __load(r0, 0, t, r0)
                        jump.patch()

                        RegZeroSlot(self)
                    },

                    t => throw BpfError("unsupported type for Subscript: {t}")
                }
            },

            ty.In(x, xs) => {
                let xs0 = __analyze(xs)
                let x0  = __analyze(x)

                let sz = match xs0 {
                    Hash(k0, _) => size-of(k0),
                    _           => throw BpfError("`in` target must be a hash or array")
                }

                let ^_xs = __emit(xs).spill()
                let ^_x  = __emit(x).spill()

                let ^_ = __load-key(_x, x0, sz)
                _xs.load(r1)
                __asm.mov64(r2, r0)
                __asm.call(helper.map_lookup_elem)
                let jump = __asm.jeq64(r0, 0)
                __asm.imov64(r0, 1)
                jump.patch()

                RegZeroSlot(self)
            },

            _ => { pp(expr); throw BpfError("unsupported expression: {expr}") }
        }
    }

    global(name: String, m: map.BpfMap, t: BpfType) -> Var {
        let var = __var(name)
        var.map = m
        var.type = t
        var
    }

    __fixup() {
        __ast = ty.walk(__ast, expr -> match expr {
            ty.SpecialString([_]) => expr,

            ty.SpecialString(parts) => do {
                let new-parts = []

                for match parts {
                    (expr, ty.SpecialString([fmt]), width, fun) => {
                        new-parts.push((expr, ty.String(fmt), width, fun))
                    },

                    part => {
                        new-parts.push(part)
                    }
                }

                ty.SpecialString(new-parts)
            },

            _ => expr
        })

        __ast = ty.walk(__ast, expr -> match expr {
            ty.SpecialString(parts) => do {
                let new-parts = [(nil, nil, #__fmts, nil)]
                let key = []

                for match parts {
                    (expr, _fmt, width, fun) => {
                        let fmt = match _fmt {
                            ty.String(fmt) => fmt,
                            _              => nil
                        }
                        new-parts.push((expr, nil, width, fun))
                        key.push({
                            fmt,
                            width,
                            type: nil,
                            fun: (fun != nil) ?: ty.eval(fun)
                        })
                    },

                    string => key.push(string)
                }

                __fmts.push(key)

                ty.SpecialString(new-parts)
            },

            _ => expr
        })
    }

    compile() {
        __fixup()
        __analyze(__ast)

        __stack-alloc = StackAllocator(__var-off, __asm)

        // Store ctx (r1) on stack if we have it
        if 'ctx' in __env {
            __asm.stx64(rbp, r1, __offset('ctx'))
        }

        if let $pidq = __env['__pidq'] {
            pidq.type = RingBuffer
            pidq.map  = __context.pid-queue
        }

        if let $pids = __env['__pids'] {
            pids.type = Hash(U64, Time64)
            pids.map  = __context.pid-filter
        }

        for name, var in __env {
            if let $m = var.map {
                if m :: map.Array {
                    __asm.ld_map_value(r1, m.fd, 0)
                    __asm.stx64(rbp, r1, -var.off)
                } else {
                    __asm.ld_map_fd(r1, m.fd)
                    __asm.stx64(rbp, r1, -var.off)
                }
            }
        }

        if 'comm' in __env {
            __var('comm').load-addr(r1)
            __asm.imov64(r2, 16)
            __asm.call(helper.get_current_comm)
        }

        if 'pid' in __env || 'tgpid' in __env {
            __asm.call(helper.get_current_pid_tgid)
            if 'tgid' in __env {
                __asm.mov64(r1, r0)
                __asm.shr64i(r1, 32)
                __asm.stx64(rbp, r1, __offset('tgid'))
            }
            if 'pid' in __env {
                __asm.and64i(r0, 0xFFFFFFFF)
                __asm.stx32(rbp, r0, __offset('pid'))
            }
        }

        __asm.call(helper.get_smp_processor_id)
        __asm.stx32(rbp, r0, __offset('cpu'))

        __asm.note('----- begin main program -----')

        __emit(__ast)

        __asm.imov64(r0, 0)
        __asm.exit()
    }

    load(debug: Bool = false) {
        __fd = load-bpf-prog(__asm, __type, debug)
        for __tracing {
            it.set-bpf(__fd)
            it.enable()
        }
    }

    unload() {
        for __tracing {
            it.disable()
        }
        if __fd != nil {
            close(__fd)
            __fd = cast(nil)
        }
    }

    array(name: String, count: Int, value-size: Int) -> map.Array {
        if let $var = __env[name] {
            var.map
        } else {
            let var = __var(name)
            var.type = U64
            var.map = map.Array(count, value-size)
        }
    }

    ringbuf(name: String) -> map.RingBuffer {
        if let $var = __env[name] {
            var.map
        } else {
            let var = __var(name)
            var.type = RingBuffer
            var.map = map.RingBuffer()
        }
    }

    attach(event: PerfEvent) {
        if event :: TraceEvent {
            __var('comm', size=16).type = Str(16)
            __var('pid').type = U32
            __var('tgid').type = U32
            __var('ctx').type = KernelPtr(Struct(event.ctx))
        }
        __tracing.push(event.open())

    }

    asm -> BpfAssembler {
        __asm
    }

    out -> map.RingBuffer {
        __output.map
    }

    stacks -> map.StackTraces {
        __stacks.map
    }
}

pub ns map {
    trait BpfMap {
        fd      -> Int;
        value() -> Any;
    }

    pub class RingBuffer : BpfMap {
        __cap:   Int
        __attr:  bpf_attr_map_create
        __fd:    Int
        __p-pos: Ptr[Int]
        __c-pos: Ptr[Int]
        __data:  Ptr[Int]

        init(capacity: Int = RING_BUFFER_CAPACITY) {
            if capacity % PAGE_SIZE != 0 {
                throw BpfError("capacity must be a multiple of the page size ({PAGE_SIZE})")
            }

            __cap = capacity

            __attr = bpf_attr_map_create()
            __attr.map_type = BPF_MAP_TYPE_RINGBUF
            __attr.max_entries = capacity
            __fd = bpf(BPF_MAP_CREATE, __attr)

            if __fd < 0 {
                throw OSError('bpf(BPF_MAP_CREATE)')
            }

            __c-pos = mmap(nil, PAGE_SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, __fd, 0)
            if __c-pos == nil {
                throw OSError('mmap()')
            }

            __p-pos = mmap(nil, PAGE_SIZE, PROT_READ, MAP_SHARED, __fd, PAGE_SIZE)
            if __p-pos == nil {
                throw OSError('mmap()')
            }

            __data = mmap(nil, 2 * capacity, PROT_READ, MAP_SHARED, __fd, 2 * PAGE_SIZE)
            if __data == nil {
                throw OSError('mmap()')
            }
        }

        pending? -> Bool {
            let p = atomic.load(c.u32, __p-pos)
            let c = atomic.load(c.u32, __c-pos)
            p != c
        }

        fd -> Int {
            __fd
        }

        try-read(out: Blob | nil = nil) -> Blob | nil {
            let _p = atomic.load(c.u32, __p-pos)
            let _c = atomic.load(c.u32, __c-pos)

            if (_p - _c) >= __cap {
                atomic.store(c.u32, __c-pos, _p)
                return nil
            }

            if _p == _c {
                return nil
            }

            let off    = _c & (__cap - 1)
            let record = __data + off
            let header = c.load(c.u64, record)

            if header & BPF_RINGBUF_BUSY_BIT {
                return nil
            }

            let discard? = header & BPF_RINGBUF_DISCARD_BIT
            let size     = header & BPF_RINGBUF_SIZE_MASK

            if !discard? {
                out = out ?? Blob()
                out.push(record + 8, size)
            } else {
                out = nil
            }

            _c = _c + ((8 + size + 7) & ~7)
            atomic.store(c.u32, __c-pos, _c)

            out
        }

        value() -> Any {
            self
        }
    }

    pub class Array : BpfMap {
        __attr:  bpf_attr_map_create
        __fd:    Int

        init(count: Int, value-size: Int) {
            __attr = bpf_attr_map_create()
            __attr.map_type = BPF_MAP_TYPE_ARRAY
            __attr.key_size = 4
            __attr.value_size = value-size
            __attr.max_entries = count
            __fd = bpf(BPF_MAP_CREATE, __attr)
            if __fd < 0 {
                throw OSError('bpf(BPF_MAP_CREATE)')
            }
        }

        fd -> Int {
            __fd
        }

        #() -> Int {
            __attr.max_entries
        }

        size -> Int {
            __attr.max_entries * __attr.value_size
        }

        [](i: Int) -> Blob {
            let key = c.box(c.u32, i)
            let value = c.alloc(__attr.value_size)

            let attr = bpf_attr_map_elem()
            attr.map_fd = __fd
            attr.key    = key
            attr.value  = value

            if bpf(BPF_MAP_LOOKUP_ELEM, attr) < 0 {
                throw OSError('bpf(BPF_MAP_LOOKUP_ELEM)')
            }

            Blob(c.as_str(value, __attr.value_size))
        }

        value() -> Any {
            self
        }
    }

    pub class PerCPUArray : BpfMap {
        __attr:  bpf_attr_map_create
        __fd:    Int

        init(count: Int, value-size: Int) {
            __attr = bpf_attr_map_create()
            __attr.map_type = BPF_MAP_TYPE_PERCPU_ARRAY
            __attr.key_size = 4
            __attr.value_size = value-size
            __attr.max_entries = count
            __fd = bpf(BPF_MAP_CREATE, __attr)
            if __fd < 0 {
                throw OSError('bpf(BPF_MAP_CREATE)')
            }
        }

        fd -> Int {
            __fd
        }

        #() -> Int {
            __attr.max_entries
        }

        size -> Int {
            __attr.max_entries * __attr.value_size
        }

        value() -> Any {
            self
        }
    }

    pub class Hash : BpfMap {
        __attr:       bpf_attr_map_create
        __fd:         Int
        __key-type:   BpfType
        __key-size:   Int
        __value-type: BpfType
        __value-size: Int

        init(key-type: BpfType, value-type: BpfType, max-buckets: Int = 1024) {
            __key-type = key-type
            __key-size = size-of(key-type)
            __value-type = value-type
            __value-size = size-of(value-type)
            __attr = bpf_attr_map_create(
                map_type=BPF_MAP_TYPE_HASH,
                key_size=__key-size,
                value_size=__value-size,
                max_entries=max-buckets
            )
            __fd = bpf(BPF_MAP_CREATE, __attr)
            if __fd < 0 {
                throw OSError('bpf(BPF_MAP_CREATE)')
            }
        }

        fd -> Int {
            __fd
        }

        key-type -> BpfType {
            __key-type
        }

        key-size -> Int {
            __key-size
        }

        value-type -> BpfType {
            __value-type
        }

        value-size -> Int {
            __value-size
        }

        dump[K, V](
            key-func: (String -> K) = Blob,
            val-func: (String -> V) = Blob
        ) -> Array[(K, V)] {
            let cursor      = c.auto(c.alloc(__key-size))
            let next-cursor = c.auto(c.alloc(__key-size))
            let value-buf   = c.auto(c.alloc(__value-size))

            let attr = bpf_attr_map_elem(
                map_fd=__fd,
                key=nil,
                value=next-cursor
            )
            defer c.free(attr)

            let results = []

            // Get first key
            if bpf(BPF_MAP_GET_NEXT_KEY, attr) < 0 {
                return results
            }

            for (;;) {
                c.memcpy(cursor, next-cursor, __key-size)

                // Lookup value
                attr.key   = cursor
                attr.value = value-buf
                if bpf(BPF_MAP_LOOKUP_ELEM, attr) == 0 {
                    //let key = ptr.typed(cursor, c.u64)
                    //let key = tuple(*(key[it] for ..(__key-size / 8)))
                    results.push((
                        key-func(c.as_str(cursor, __key-size)),
                        val-func(c.as_str(value-buf, __value-size))
                    ))
                }

                // Get next key
                attr.value = next-cursor
                if bpf(BPF_MAP_GET_NEXT_KEY, attr) < 0 {
                    break
                }
            }

            return results
        }
    }

    class BloomFilter : BpfMap {
        __attr:  bpf_attr_map_create
        __fd:    Int

        init(value-size: Int, entries: Int = 16384) {
            __attr = bpf_attr_map_create()
            __attr.map_type = BPF_MAP_TYPE_BLOOM_FILTER
            __attr.key_size = 0
            __attr.value_size = value-size
            __attr.max_entries = entries
            __fd = bpf(BPF_MAP_CREATE, __attr)
            if __fd < 0 {
                throw OSError('bpf(BPF_MAP_CREATE)')
            }
        }

        fd -> Int {
            __fd
        }
    }

    class LruHash : BpfMap {
        __attr:  bpf_attr_map_create
        __fd:    Int
        __value-type: BpfType

        init(key-size: Int, value-type: BpfType, max-buckets: Int = 1024) {
            __attr = bpf_attr_map_create()
            __attr.map_type = BPF_MAP_TYPE_LRU_HASH
            __attr.key_size = key-size
            __attr.value_size = size-of(value-type)
            __attr.max_entries = max-buckets
            __fd = bpf(BPF_MAP_CREATE, __attr)
            __value-type = value-type
            if __fd < 0 {
                throw OSError('bpf(BPF_MAP_CREATE)')
            }
        }

        fd -> Int {
            __fd
        }
    }

    class StackTraces : BpfMap {
        __attr:  bpf_attr_map_create
        __fd:    Int

        init(capacity: Int = MAX_STACK_TRACES) {
            __attr = bpf_attr_map_create()
            __attr.map_type = BPF_MAP_TYPE_STACK_TRACE
            __attr.key_size = 4
            __attr.value_size = STACK_TRACE_SIZE
            __attr.max_entries = capacity
            __fd = bpf(BPF_MAP_CREATE, __attr)
            if __fd < 0 {
                throw OSError('bpf(BPF_MAP_CREATE)')
            }
        }

        fd -> Int {
            __fd
        }

        [](id: Int) -> Array[Int] | nil {
            let len = STACK_TRACE_SIZE / c.size(c.ptr)
            let key = c.box(c.u32, id)
            let value = c.new(c.u64, len)

            let attr = bpf_attr_map_elem()
            attr.map_fd = __fd
            attr.key    = key
            attr.value  = value

            if bpf(BPF_MAP_LOOKUP_ELEM, attr) < 0 {
                return nil
            }

            [value[it] for ..len while value[it] != 0]
        }
    }
}

pub class PerfEvent {
    open() -> EventHandle;
}

pub class TraceEvent < PerfEvent {
    __name:     String
    __id:       Int
    __ctx:      Dict[String, (Int, BpfType)]

    name -> String {
        __name
    }

    ctx -> Dict[String, (Int, BpfType)] {
        __ctx
    }

    static __get-id(name: String) -> Int {
        if let $content = slurp("{TRACEFS_PATH}/events/{name}/id") {
            int(content.strip())
        } else {
            throw BpfError("failed to read tracepoint ID for {name}")
        }
    }

    static __get-format(name: String) -> String {
        if let $content = slurp("{TRACEFS_PATH}/events/{name}/format") {
            content
        } else {
            throw BpfError("failed to read tracepoint format for {name}")
        }
    }

    static __load-ctx(tracepoint: String) -> Dict[String, (Int, BpfType)] {
        let format = __get-format(tracepoint)

        let fields = format
            .lines()
            .filter!(/^\s*field:/)
            .map(\_.split('\t'))
            .map(match [_, field, offset, *] => (
                field.comb(/^field:|;/),
                offset.comb(/^offset:|;/).int
            ))

        let ctx = %{}

        for (field, off) in fields {
            let (ident, type) = ctx-arg-type(field)
            ctx[ident] = (off, type)
        }

        ctx
    }


    init(name: String) {
        __name = name
        __id   = __get-id(name)
        __ctx  = __load-ctx(name)
    }

    open() -> EventHandle {
        let attr = perf_event_attr(
            type=PERF_TYPE_TRACEPOINT,
            size=#perf_event_attr,
            config=__id,
            sample_period_or_freq=1,
            flags=1  // disabled
        )

        let fd = for (;;) {
            let fd = c.syscall(
                SYS_perf_event_open,
                (c.ptr, attr),
                (c.int, -1),
                (c.int, 0),
                (c.int, -1),
                (c.ulong, 0)
            )

            break fd if fd >= 0

            if errno.get() != errno.EINTR {
                throw OSError('perf_event_open()')
            }
        }

        EventHandle(fd, self)
    }
}

pub class EventHandle {
    __fd:       Int
    __event:    PerfEvent
    __bpf-fd:   Int
    __enabled?: Bool

    init(fd: Int, event: TraceEvent) {
        __fd = fd
        __event = event
        __bpf-fd = -1
        __enabled? = false
    }

    set-bpf(fd: Int) {
        let ret = ioctl(__fd, PERF_EVENT_IOC_SET_BPF, (c.int, fd))
        if ret < 0 {
            throw OSError('ioctl(PERF_EVENT_IOC_SET_BPF)')
        }
        __bpf-fd = fd
    }

    enable() {
        let ret = ioctl(__fd, PERF_EVENT_IOC_ENABLE, (c.int, 0))
        if ret < 0 {
            throw OSError('ioctl(PERF_EVENT_IOC_ENABLE)')
        }
        __enabled? = true
    }

    disable() {
        let ret = ioctl(__fd, PERF_EVENT_IOC_DISABLE, (c.int, 0))
        if ret < 0 {
            throw OSError('ioctl(PERF_EVENT_IOC_DISABLE)')
        }
        __enabled? = false
    }

    enabled? -> Bool {
        __enabled?
    }

    event -> PerfEvent {
        __event
    }
}

fn which(cmd: String) -> String | nil {
    if not let $path = getenv('PATH') {
        return nil
    }
    for dir in path.split(':') {
        let path = Path(dir) / cmd
        if path.executable? {
            return str(path)
        }
    }
}

fn find-lib(name: String) -> String | nil {
    let pattern = regex("^\\s*{name}(?:\\.so(?:\\.\\d+)*)? [^=]*=>\\s+(.+)$")
    for line in sh('ldconfig -p').lines() {
        if let [_, path] = line.match(pattern) {
            return path
        }
    }
}

pub class UprobeEvent < TraceEvent {
    __name:   String
    __file:   String
    __offset: Int
    __args:   Dict[String, (Int, BpfType)] = %{}

    static __regs: Dict[String, (Int, BpfType)] = %{
        'arg0': (112, U64),
        'arg1': (104, U64),
        'arg2': (96,  U64),
        'arg3': (88,  U64),
        'arg4': (80,  U64),
        'arg5': (72,  U64),
        'ret':  (128, U64),
        'sp':   (152, U64),
        'ip':   (136, U64),
        'bp':   (32,  U64)
    }

    init(name: String, file: String, offset: Int) {
        __name   = name
        __file   = file
        __offset = offset

        let fd = os::open("{TRACEFS_PATH}/uprobe_events", O_RDWR | O_CLOEXEC)
        if fd < 0 {
            throw OSError('open(uprobe_events)')
        }

        // Remove existing event with the same name
        if (Path("{TRACEFS_PATH}/events/uprobes/{__name}")).exists? {
            Path("{TRACEFS_PATH}/events/uprobes/{__name}/enable").write('0\n')
            if write(fd, "-:{__name}\n") < 0 {
                defer close(fd)
                throw OSError('write(uprobe_events)')
            }
        }

        if write(fd, dbg("p:{__name} {__file}:{__offset}\n")) < 0 {
            defer close(fd)
            throw OSError('write(uprobe_events)')
        }

        close(fd)

        super("uprobes/{__name}")
    }

    init(name: String, binary: String, func: String) {
        debug!("creating UprobeEvent for function {func} in binary {binary}")
        if '/' not in binary {
            if let $path = which(binary) {
                binary = path
            } else if let $lib = find-lib(binary) {
                binary = lib
            } else {
                throw BpfError("failed to locate binary or library: {binary}")
            }
        }
        if let [(_, offset, args), *] = dbg(dwarf::lookup2(binary, func)) {
            let offs = [112, 104, 96, 88, 80, 72]
            __args = %{name: (offs[i], ctx-arg-type(type).1) for (name, type), i in args}
            init(name, binary, offset)
        } else {
            throw BpfError("failed to find function {func} in {binary}")
        }
    }

    ctx -> Dict[String, (Int, BpfType)] {
        __regs + __args
    }
}

class IntervalEvent < PerfEvent {
    __period: Int

    init(period: Int) {
        debug!("creating IntervalEvent with period {period}")
        __period = period
    }

    open() -> EventHandle {
        let attr = perf_event_attr(
            type=PERF_TYPE_SOFTWARE,
            size=#perf_event_attr,
            config=PERF_COUNT_SW_CPU_CLOCK,
            sample_period_or_freq=__period,
            flags=1  // disabled
        )

        let fd = for (;;) {
            let fd = c.syscall(
                SYS_perf_event_open,
                (c.ptr, attr),
                (c.int, -1),
                (c.int, 0),
                (c.int, -1),
                (c.ulong, 0)
            )

            break fd if fd >= 0

            if errno.get() != errno.EINTR {
                throw OSError('perf_event_open()')
            }
        }

        EventHandle(fd, self)
    }
}

fn add-log-buf(attr: bpf_attr_prog_load, level: Int = 1) {
    attr.log_buf = c.alloc(655360)
    attr.log_size = 655360
    attr.log_level = level
}

fn load-bpf-prog(prog: BpfAssembler, type: Int, debug: Bool = false) -> Int {
    let attr = bpf_attr_prog_load()
    attr.prog_type = type
    attr.insns     = prog
    attr.insn_cnt  = #prog
    attr.license   = c.c_str('GPL')

    if debug {
        add-log-buf(attr, 2)
    }

    let fd = bpf(BPF_PROG_LOAD, attr)
    if fd < 0 {
        if !debug {
            add-log-buf(attr)
            bpf(BPF_PROG_LOAD, attr)
        }
        eprint(c.as_str(attr.log_buf))
        throw OSError('bpf(BPF_PROG_LOAD)')
    }

    if debug {
        eprint(c.as_str(attr.log_buf))
    }

    fd
}

pub class PrettyHistogram {
    __data: Array[Int]

    static bins: Array[String] = [
        '0-1',
        '2-3',
        '4-7',
        '8-15',
        '16-31',
        '32-63',
        '64-127',
        '128-255',
        '256-511',
        '512-1K',
        '1K-2K',
        '2K-4K',
        '4K-8K',
        '8K-16K',
        '16K-32K',
        '32K-64K',
        '64K-128K',
        '128K-256K',
        '256K-512K',
        '512K-1M',
        '1M-2M',
        '2M-4M',
        '4M-8M',
        '8M-16M',
        '16M-32M',
        '32M-64M',
        '64M-128M',
        '128M-256M',
        '256M-512M',
        '512M-1G',
        '1G-2G',
        '2G-4G',
        '4G-8G',
        '8G-16G',
        '16G-32G',
        '32G-64G',
        '64G-128G',
        '128G-256G',
        '256G-512G',
        '512G-1T',
        '>1T'
    ]

    static label(n: Int) -> String {
        bins[min(n, #bins - 1)]
    }

    init(data: Array[Int]) {
        __data = data
    }

    __pretty__*() {
        let lo    = 0
        let hi    = __data.searchr-by(\_ > 0)
        let total = __data.sum()

        let lines = []

        yield pretty::Raw('[')
        yield pretty::Push

        for i in lo...hi {
            let [a, ?b] = label(i).split('-')
            let label = "[{"{a},":<5} {b ?? '...':>5})"
            let count = __data[i]
            let width = iround(count * 40.0 / total)
            let bar   = "|{('@' * width).rpad(40)}|"
            yield pretty::Raw(chalk"    [bright yellow]{label:-10}[/]  [bright cyan]{count:8}[/]  [bright blue]{bar}[/]")
            if i != hi {
                yield pretty::Newline
            }
        }

        yield pretty::Pop
        yield pretty::Raw(']')
    }
}

pub class PrettyStackTrace {
    __trace: Array[(String, (String, Int, Int) | nil) | nil]

    static nice(location: Int) -> chalk::Text {
        match location {
            (name, (file, line, col)) => chalk"[bright green]{name:32}[/] "
                                              "[blue]at[/] [bright yellow]{file}[/]"
                                              "[bright magenta]:{line}:{col}[/]",
            (name, nil)               => chalk"[bright green]{name:32}[/] "
                                              "[blue]at[/] [#888]<unknown>[/]",
            nil                       => chalk"[bright red]{'??':32}[/] [blue]at[/] [#888]<unknown>[/]"
        }
    }

    init(trace: Array[(String, (String, Int, Int) | nil) | nil]) {
        __trace = trace
    }

    __pretty__*() {
        yield pretty::Raw('[')
        yield pretty::Push
        for location, i in __trace {
            yield pretty::Raw(nice(location))
            if i + 1 < #__trace {
                yield pretty::Newline
            }
        }
        yield pretty::Pop
        yield pretty::Raw(']')
    }

    __str__() -> String {
        pretty(self)
    }
}

pub fn histogram(data: IntoPtr[Int]) {
    let data  = ptr.typed(data.__ptr__(), c.u64)
    let val   = [data[it] for ..64]
    PrettyHistogram(val)
}

pub class BpfContext {
    __progs:  Array[BpfProgram]
    __maps:   Dict[String, map.BpfMap]
    __stacks: map.StackTraces
    __pidq:   map.RingBuffer
    __pids:   map.LruHash
    __ctxs:   Dict[String, dwarf::Context]
    __cache:  Dict[Int, String]
    __cacheq: SharedQueue[(Int, String)]
    __cacher: Thread[_]

    init() {
        __progs  = []
        __maps   = %{}
        __stacks = map.StackTraces()
        __pidq   = map.RingBuffer()
        __pids   = map.LruHash(4, Time64)
        __ctxs   = %{}
        __cache  = %{}
        __cacheq = SharedQueue()
        __cacher = Thread(__run-cacher)
    }

    __run-cacher() {
        let events = []
        for (;;) {
            if poll([__pidq.fd], events, -1) < 0 {
                sleep(0.1)
                continue
            }
            while let $record = __pidq.try-read() {
                let pid = c.load(c.u32, record)
                if let $maps = slurp("/proc/{pid}/maps") {
                    __cacheq.put((pid, maps))
                } else {
                    warn!("failed to cache /proc/{pid}/maps")
                }
            }
        }
    }

    array(name: String, count: Int = 1, value-size: Int = 8) -> map.Array {
        match __maps[name] {
            m: map.Array => m,
            nil          => (__maps[name] = map.Array(count, value-size)),
            _            => throw BpfError("map name conflict: {name}")
        }
    }

    per-cpu-array(name: String, count: Int = 1, value-size: Int = 8) -> map.PerCPUArray {
        match __maps[name] {
            m: map.PerCPUArray => m,
            nil                => (__maps[name] = map.PerCPUArray(count, value-size)),
            _                  => throw BpfError("map name conflict: {name}")
        }
    }

    hash(
        name: String,
        key-type: BpfType,
        value-type: BpfType,
        max-buckets: Int = 1024
    ) -> map.Hash {
        match __maps[name] {
            m: map.Hash => m,
            nil         => (__maps[name] = map.Hash(key-type, value-type, max-buckets)),
            _           => throw BpfError("map name conflict: {name}")
        }
    }

    __compile() {
        for prog in __progs {
            prog.compile()
        }
    }

    prog(type: Int, ast: AST) -> BpfProgram {
        let prog = BpfProgram(type, ast, self)
        __progs.push(prog)
        __progs[-1]
    }

    tracepoint(ast: AST) -> BpfProgram {
        prog(BPF_PROG_TYPE_TRACEPOINT, ast)
    }

    kprobe(ast: AST) -> BpfProgram {
        prog(BPF_PROG_TYPE_KPROBE, ast)
    }

    perf-event(ast: AST) -> BpfProgram {
        prog(BPF_PROG_TYPE_PERF_EVENT, ast)
    }

    pid-queue -> map.RingBuffer {
        __pidq
    }

    pid-filter -> map.LruHash {
        __pids
    }

    proc-maps -> SharedQueue[(Int, String)] {
        __cache
    }

    progs -> Array[BpfProgram] {
        __progs
    }

    maps -> Dict[String, map.BpfMap] {
        __maps
    }

    stacks -> map.StackTraces {
        __stacks
    }

    dwarf-ctx(maps: String) -> dwarf::Context {
        match __ctxs[maps] {
            $ctx => ctx,
            nil  => (__ctxs[maps] = dwarf::Context(maps))
        }
    }

    @memoized(max=8192)
    stack(key: Int) {
        let id    = key >> 32
        let pid   = key & 0xFFFFFFFF
        let trace = match __stacks[id] {
            $addrs and let $maps = __cache[pid] => do {
                catch _ {
                    []
                }
                let ctx = dwarf-ctx(maps)
                [ctx.resolve(it) for it in addrs]
            },
            _ => []
        }
        PrettyStackTrace(trace)
    }

    value(t0: BpfType, data: IntoPtr[Any]) -> Any {
        match t0 {
            U8  => c.load(c.u8, data),
            I8  => c.load(c.i8, data),
            U16 => c.load(c.u16, data),
            I16 => c.load(c.i16, data),
            U32 => c.load(c.u32, data),
            I32 => c.load(c.i32, data),
            U64 => c.load(c.u64, data),
            I64 => c.load(c.i64, data),

            Time64 => Moment(c.load(c.u64, data) / 1.0e9),

            AnyPtr(I8 or Str(_)) or Str(_) => c.str(data),

            MapRef((m: map.Hash)) => pretty(%{
                key: val
                for (key, val) in m.dump(
                    value@(m.key-type, _),
                    value@(m.value-type, _)
                )
            }),

            MapRef(m) => m,

            UStack => stack(c.load(c.u64, data)),
            KStack => stack(c.load(c.u64, data)),

            Histogram => histogram(data),

            Record(fields) => do {
                let data = data.__ptr__()
                let vals = []
                for field in fields {
                    vals.push(value(field, data))
                    data += align(size-of(field))
                }
                tuple(*vals)
            },

            _   => throw BpfError("unsupported bpf type: {t0}")
        }
    }

    run() {
        __compile()

        for __progs {
            //print("BPF program: ({#it.asm} instructions)")
            //print(it.asm.dis)
            it.load()
        }

        let buffers = %{*: Blob()}
        let last-cleanup = time.now()

        let stop = false

        signal(SIGINT, () -> do { stop = true; })

        let events = []

        while !stop {
            while let Some((pid, maps)) = __cacheq.try-take() {
                __cache[pid] = maps
            }
            if poll([(it.out.fd, POLLIN, it) for it in __progs], events, 0.25) <= 0 {
                continue
            }
            for (_, _, prog) in events {
                while let $data = prog.out.try-read() and !stop {
                    //print("data: {#data} bytes")
                    //print("      {["{c:02x}" for c in data].unwords()}")

                    let ptr = data.ptr()

                    let string-id = c.load(c.u32, ptr)
                    ptr += 4

                    let tid = c.load(c.u64, ptr)
                    ptr += 8

                    let specs = prog.strings[string-id]
                    let buf = buffers[tid]

                    for spec in specs {
                        match spec {
                            {type: $t, fmt, fun, *} => {
                                let val = value(t, ptr)

                                let text  = fmt ? "{val:{fmt}}" : "{val}"
                                buf.push(fun ? fun(text) : text)

                                ptr += match t {
                                    StringLike => val.size() + 1,
                                    _          => size-of(t)
                                }
                            },

                            (s: String) => buf.push(s)
                        }
                    }

                    while let $i = buf.search(0x0a) {
                        let line = buf.splice(0, i + 1).str!()
                        print(line, end='')
                    }
                }
            }
            if (time.now() - last-cleanup) > 1.0 {
                buffers.keep!((_, buf) -> #buf != 0)
                last-cleanup = time.now()
            }
            sleep(0.001)
        }

        for progs {
            it.unload()
        }
    }
}
